{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# module name here\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from sklearn.tree import BaseDecisionTree\n",
    "from functools import partial\n",
    "from numpy.polynomial.chebyshev import Chebyshev\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def shift_bit_eps(bit: int, eps: float = 0.5):\n",
    "    assert bit in [0,1], \"Bit must be 0 or 1\"\n",
    "    return (2 * eps - 1) * bit + 1 - eps\n",
    "\n",
    "def create_base_vectors(circuit: List[int], eps: float = 0.5):\n",
    "    vectors = []\n",
    "    n = len(circuit)\n",
    "    \n",
    "    for i in range(n):\n",
    "        vector = list(circuit).copy()\n",
    "        vector[i] = shift_bit_eps(vector[i], eps=eps)\n",
    "        vectors.append(vector)\n",
    "        \n",
    "    return vectors\n",
    "\n",
    "def create_linear_system(vectors: List[List[float]]):\n",
    "    X = np.array(vectors)\n",
    "\n",
    "    y = -X[:,-1]\n",
    "\n",
    "    X[:,-1] = 1\n",
    "    \n",
    "    return X,y\n",
    "\n",
    "class BitComparison(nn.Module):\n",
    "    def __init__(self,target: List[int], eps : float = 0.5):\n",
    "        super(BitComparison, self).__init__()\n",
    "                \n",
    "        vectors = create_base_vectors(target, eps=eps)\n",
    "        X,y = create_linear_system(vectors)\n",
    "        W = np.linalg.solve(X,y)\n",
    "        w = W[:-1]\n",
    "        w = np.concatenate([w,np.ones(1)])\n",
    "        c = W[-1]\n",
    "        \n",
    "        if not target[-1]:\n",
    "            w = -w\n",
    "            c = -c\n",
    "            \n",
    "        n = len(target)\n",
    "        self.n = n\n",
    "        self.linear = nn.Linear(n,1)\n",
    "        \n",
    "        self.linear.weight.data = torch.tensor(w.reshape(1,-1)).float()\n",
    "        self.linear.bias.data = torch.tensor(c).unsqueeze(0).float()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.linear(x)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        output = \"\"\n",
    "        for i in range(self.n):\n",
    "            if i < self.n - 1:\n",
    "                output += f\"{self.linear.weight.data[0][i]}*x_{i} + \"\n",
    "            else:\n",
    "                output += f\"{self.linear.weight.data[0][i]}*y + \"\n",
    "        output += f\"{self.linear.bias.data[0]} = 0\"\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def create_test_cases_x(n):\n",
    "    products = [[0,1]] * n\n",
    "\n",
    "    x = list(itertools.product(*products))\n",
    "    x = np.array(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def create_test_cases_y(x,target):\n",
    "    y = ((x == target).sum(axis=1) == n).astype(int)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.25\n",
    "n = 7\n",
    "\n",
    "x = create_test_cases_x(n)\n",
    "\n",
    "for target in x:\n",
    "    y = create_test_cases_y(x,target)\n",
    "    y = torch.tensor(y)\n",
    "    \n",
    "    bitcomparison = BitComparison(target, eps=eps)\n",
    "    accuracy = (y == (bitcomparison.linear(torch.tensor(x).float()) > 0).view(-1)).float().mean().item()\n",
    "    \n",
    "    assert accuracy == 1, f\"Accuracy inferior to 1 {accuracy}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0*x_0 + 1.0*x_1 + 1.0*x_2 + 1.0*x_3 + 1.0*x_4 + 1.0*x_5 + 1.0*y + -6.25 = 0\n"
     ]
    }
   ],
   "source": [
    "print(bitcomparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from numpy.polynomial import Polynomial\n",
    "\n",
    "def chebyshev_approximation(f, dilatation_factor=50, polynomial_degree=25, bound=1, convertToTensor=True):\n",
    "    if convertToTensor:\n",
    "        f_a = lambda x: f(torch.tensor(x*dilatation_factor))\n",
    "    else:\n",
    "        f_a = lambda x: f(x*dilatation_factor)\n",
    "        \n",
    "    domain = [-bound,bound]\n",
    "\n",
    "    p = Chebyshev.interpolate(f_a,deg=polynomial_degree,domain=domain)\n",
    "    return p, f_a\n",
    "\n",
    "def polynomial_approximation_coefficients(f, dilatation_factor=50, polynomial_degree=25, \n",
    "                                          bound=1, convertToTensor=True):\n",
    "    p,_ = chebyshev_approximation(f, dilatation_factor, polynomial_degree, bound, convertToTensor)\n",
    "    \n",
    "    return Polynomial.cast(p).coef\n",
    "\n",
    "def plot_graph_function_approximation(f, dilatation_factor=50, polynomial_degree=25, bound=1, convertToTensor=True):\n",
    "    \n",
    "    p, f_a = chebyshev_approximation(f, dilatation_factor, polynomial_degree, bound, convertToTensor)\n",
    "    \n",
    "    x = np.linspace(*domain,100)\n",
    "    y = f_a(x)\n",
    "    pred = p(x)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # plot the function\n",
    "    ax.plot(x,y, 'g', label=\"Sigmoid\")\n",
    "    ax.plot(x,pred,\"b-\", label=f\"Polynomial approximation\")\n",
    "    ax.legend()\n",
    "\n",
    "    # show the plot\n",
    "    fig.suptitle(f\"Tchebytchev polynomials with expansion a={dilatation_factor} and degree n={polynomial_degree}\")\n",
    "    fig.show()\n",
    "    \n",
    "    return fig,ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6oAAAEVCAYAAADpfxiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdeZxcVZn/8c9T1VW9d5burCQhLGFNCEsnQdkCAiIKCQFlWI0oiAwo+JMRlVGEUcFhHHRwhgmLYYcZdQAxDIKQYREMiYkQZAsYTCAh6c7We23n98e91anuVHe6uyq5Vd3f9+tVr1rOXZ5bt6pOPfece6455xAREREREREpFKGgAxARERERERHJpERVRERERERECooSVRERERERESkoSlRFRERERESkoChRFRERERERkYKiRFVEREREREQKihJVEdllzMyZ2b67e95CXM9AmdlkP8aSoGPJZGbNZrZ3H6bbpfGb2W1m9o+9lF9nZvftinUHbWfbLgPTn9+Ewfz5EhEJmhJVEekTPzFJ31Jm1pbx/Lyg40szs9lmtjboOAY751yVc+69AojjUufcDTD09n3mthciM7vBzF4zs4SZXdet7NNm9oKZbTGz9WZ2h5lVZ5QvNLNYt9+d8G7fCOnCzBaY2Vt+HTC/W9nnzWyZmW0zs7Vm9uPMA1T+QatFZrbZ3+e3FtoBOBEpLEpURaRP/MSkyjlXBfwNOC3jtfuDjk9ECs4q4B+A32YpGwb8EzAeOBDYA/jnbtP8OPN3xzmX3KXRFpACTuD+DFwG/ClLWQVwJVAHzAI+AXwjo/zfgQ3AOOBQ4Dh/WSIiWSlRFZGcmFnYzL5tZu+aWZN/RH1ixiQnmtk7fsvJz83MMua9yMze8I+wP2lme3Zb/Klm9p6ZNZjZP5tZyMyiZrbJzKZlLGe0mbX68z8BjM9ohRm/K2I0s/8ws5u7vRePmtnXe3ifnJl9tfv2+GUhM7vWzN43sw1mdo+ZDcuyjM+a2bJur33dzB71Hy/04/+tv51/NLN9Mqb9uJm9YmZb/fuPZ5QtNrN/MrM/+O/bb8ys1szu91tIXjGzyd22Z1//8afNbLk/3ZrurWfd4p3vvwdNZvZXy9Iab2Zl5rXY1/nPv2Neq1yN//wGM7slY5v/ycwqybLv/UVG/fe0ycxeN7P6XuI7wMye8j9jb5nZ5/zX9/FfO9x/Pt7MNprZ7Iz370dmtsR/Hx41s5EZy/1v81qRtprZc2Z2cEZZj/vNPP/qfy62mddCOTVz2zOWc7GZrfLjfCxj+9P769KePufd3oOZZvaSP90681q+oj29Zz1xzt3tnHsCaMpS9oBz7n+dc63Ouc3A7cBR/V2HH+8+ZvaMmTX63637zWx4RvlqM/uGmb3qv/8Pm1lZRvnV/nZ+aGYX7WRde5nZ//n76Sm8pCyz/Ej/O7TFzP6c/nxkzPucP+/T/j64zy9Ld5H/opn9DXjGf73H38iePqs9xL3Y/9686K//d+nvV384537unPs90J6l7D+cc88752LOuQ+A++m6T/cC/ss51+6cWw/8L3Bw9+WIiHRyzummm2669esGrAZO9B9fDbwG7A8YMB2o9csc8DgwHJgEbARO8cvm4LW4HAiUANcCf8hYhwOeBUb6874NfMkv+3fgpoxpvwb8xn88G1jbLd68xwgcC6wBzH8+AmgDxvfwnvW2PRf569kbqAJ+Ddzrl0325y0BSoFNwIEZy10OnOk/Xgg0AjP96e8HHvLLRgKbgQv8snP85+n3YbEfwz54rV1/8WM80Z/+HuAX3bZn34z3fBrewc9DgI+AuVnirwS2Afv7ZeOAg3t4v57L2K7fAe8Cn8ooOyNjm/+pl31/Hd6f6lOBMPAj4OUe1lnp79Mv+PEeBjQAB/nlF/vvSwXwJHBzxryLgQ+Aqf5yfgXcl1F+EVDt78NbgBUZZb3tt08Cy/A+n4b3WRyXZdtP8GM93F/HvwHPddtfWT/nWd6HI4Aj/VgmA28AV2aUvwps6eH271mWdx9w3U5+U25Jb3PGtm3yb8vSn4Ue5t0XOMnf7lH+5+OWbr9XS/Bab0f623OpX3YK3uc1vd8eIOOznWVdLwE/8dd1LF4Sfp9ftoe/H0/F+y6c5D8flTHvzUAUOBrvu5Ced7K/3nv8OMrp/fen189qlrgX432H9vOXvRi4MaO8p/25Bbgmy/JeAObvZJ8+0m0dX/a3r8J/r1bif49100033bLdAg9AN910K74bXRPVt4A5PUzngKMznv9X+k8PXuvXFzPKQkArsGfGvKdklF8G/N5/PAuv+3E6SVwKfM5/PJsdk5W8x4iXNPwNONYvuxh4ppf3rLft+T1wWUbZ/kCc7YmCA0r8sv8AfuA/Phgv2Sz1ny8E7shYzqnAm/7jC4Al3WJ6Kf1n0//j+p2Msn8Bnsh4fhpdk6ve/szfAvyr/7gzfrw/11uAM4HynXzGbgB+5s+3Hu9gxI1AGd4BgdqMbd5Zovp0xvODgLYe1nk28Hy31/4T+F7G88fwDnq8mn7fM96/G7utJwaEs6xnuP+eDOvDfjsB74DBkUCo23Iyt/1OvK6y6bIq/zM0eWef8z58368E/qcv0/Ywf6+JKl5CtxnYL+O1w4Faf/+fipcQHtXH9c0Flmc8Xw2cn/H8x8Bt/uO7uu23/Xr6bOMl+AmgMuO1B9iebH4T/wBTRvmTwOcz5q3o9r50T1T3zijv7fdnp5/VbmWLgWsznl8G/G8O+7TXRBXvwMxaoC7jtQPxDjok/G1diP8brptuuumW7aauvyKSq4l4R+p7sj7jcSveH2jw/mz91O8itwWv5cTwjrSnrcl4/D5eiwjOuT/6y5ptZgfgtag8tjtjdM454CG8lkmAc/FawnqTdXv8+/e7lZUAY7Is427gXL/b5gV4Xek6+rAt3deRXk/m+/1RxuO2LM+ryMLMZpnZs35X2K3ApXTrEgngnGvB+4N9KbDO7+p6QLZlAv+Hl3gejpcYPoV3TtuRwCrnXGMP82XT/T0ps+znAO4JzErvb3+fnweMzZjmdrzWt3/r9r7Djvs3AtSZ1/X8RvO6nm/DS5yg63uUdb85554BbgV+DmwwbzCbmiyxd9m/zrlmvNa8zP3b02ejCzPbz8we97sqbwN+SJb9mQ9mdiResneWc+7t9OvOuT855xqdcwnn3CK879a8HpYxxsweMrMP/HjvyxJvb9+L7vutJ+OBzf7nONv0ewKf7fb5ORqv58B4YJNzrjVj+sz1Znutt9/IvnxWu+vT/s+Vmc3F67nwKedcg/9aCK+r76/xDljV4fVCuWlXxCAig4MSVRHJ1Rq87qIDme/LzrnhGbdy59wfMqbJPI90EvBhxvO7gfPxkrVfOufS50y53Rjjg8BZ/nljs/C6e/amp+35EO+PZ2ZZgq6JIgDOuZfxWuqOwUuO7+3jtnRfR3o9H/Rx/t48gHegYKJzbhhwG94f6h045550zp2E9+f9TbzEL5s/4LUsnwH8n3PuL368p+IlsVkXP+At8Kzx15W5v6ucc18BMLMqvNbiO4HrLOMcVF/3/RvH6455Ll43zhPxulVP9qfJ+h5155z7mXPuCLxW2v3wurJ312X/mnfObi0D27//gbdvpjjnaoBvZ8Zq3nm+zT3cbuvrSszsMLzPzUXOO++xN46e368f+uXT/HjP72Xa7tax437rbdoR/nubbfo1eC2qmZ+fSufcjf68I82sImP6zPWmZX6Ge/v96fWz2l+97M9mM/t2P5ZzCt53+jTn3GsZRelTHm51znX4B5p+gfd9FhHJSomqiOTqDuAGM5tinkPMrLYP890GfMv8QWXMbJiZfbbbNFeb2QjzBj76GvBwRtl9eEnM+XjnPaV9BNRa18GIdkmMzrnleInIHcCTzrktO1leT9vzIHCVP9hKFd4f74edc4kelnMPXitb3Dn3Qh+2A2ARsJ+ZnWtmJWZ2Nl7i83gf5+9NNV5rUbuZzcRLzHbgt3zN8f/odwDNQCrbtH7L0zLg79memP4BrzW2p0Q1277vj8fx3qMLzCzi32aY2YF++U+Bpc65L+GNZNs9KTvfzA7yk5Hr8Q6gJPHenw68Fs4KvP3bJ/76Z5lZBGjBO98223v2IPAFMzvUzEr9dfzRObe6r+vKUI13/mSz3+LdJflxzh3suo7Gm3m7NCP2iHmDFoWAEvMGyQr7ZVPxWtiucM79Jst2n2VmVeYNNHYy3ve8p14T1Xifpa1mtgfZE/me/BcwP2O/fa+nCZ1z7+OdZvB98wZ1OxqvS3zafcBpZvZJvxW9zLxLJk3ImPc6f96PdZs3m95+f3b2We2XXvZnlXOu8/Pqx16GdyAg4m9jelC4E/Bavs90zi3ptvwG4K/AV/zfn+F4XaJfHUi8IjI0KFEVkVz9BO/P3u/w/tzeiTdYR6+cc/+D1+3rIb+73krgU90mexQvWVmBlxjcmTH/GrxLJDjg+YzX38T70/6e3yVu/C6O8QG8lrIHdra8XrbnLryW0efw/sy1A1f0spx78bqf3teHdQLgt2B8Bvh/eAnTPwCfSXfNy9FlwPVm1gR8F++9ziYEfB2v9W8TXlfe3lqA/g+v++ySjOfVeO/TDnrY933mnGsCTgb+zo9xPd7+LzWzOXgD76Tj/TpwuHUdtfhevPPu1uOdS/tV//V78LqIfoA3GNPL/QirBq+FarO/jEZ2vIwLzrmngX/Ea9Vfh9eD4O/6sZ5M38A72NDkr/vh3ifv0e14XcbPAb7jP77AL/t/eAMf3ZnRcvd6xrxfw3u/tuBt78XOucU9rOf7eF3Et+J9r37d1wCdNyrxLXij7K7y73tzLl7viU14SW3nQTL/N2kOXgv0RrxWz6vZ/l/rPOBjePvwn/De1+7dxzNj6/H3p7fPap82fOB+h7cfPw4s8B8f65f9I16PgUUZ+/SJjHnn4X2HNuK913Hgql0cr4gUsfRAJCIiRcfM7gI+dM5dG3QsO2NmDq8r5ao8LKsc73qEhzvn3sk5OMmZmS3GGxjnjqBjkeJgZg/jDZrVYyuuiMhQVqgXlBYR6ZV51/Sch3dZhqHmK8ArSlJFioeZzcBrif0rXmvoHLyRrEVEJAslqiJSdMzsBrwuYz9yzv016Hh2JzNbjXd+2NyAQxGR/hmL1y25Fu/SLV/xz3MXEZEs1PVXRERERERECooGUxIREREREZGCokRVRERERERECooSVRERERERESkoSlRFRERERESkoChRFRERERERkYKiRFVEREREREQKihJVERERERERKShKVEVERERERKSgKFEVERERERGRgqJEVURERERERAqKElUREREREREpKEpURUREREREpKAoURUREREREZGCokRVRERERERECkpJ0AH0pK6uzk2ePDnoMEREZJBYtmxZg3NuVNBxFDPVzSIikk+91c0Fm6hOnjyZpUuXBh2GiIgMEmb2ftAxFDvVzSIikk+91c3q+isiIiIiIiIFRYmqiIiIiIiIFBQlqiIiIiIiIlJQCvYc1Wzi8Thr166lvb096FBEACgrK2PChAlEIpGgQxERCYTqZik0qptFBoeiSlTXrl1LdXU1kydPxsyCDkeGOOccjY2NrF27lr322ivocEREAqG6WQqJ6maRwaOouv62t7dTW1urilAKgplRW1urVgQRGdJUN0shUd0sMngUVaIKqCKUgqLPo4iIfgulsOjzKDI4FFXXXxHJH+fgrbfgxRehtRVmz4apUyFdvzsHa9bAa69BXR3suy+MHLm9HCAWg44O7zUzCIUgGoVwuOu64nFoavLua2qgrKzrcuJxaGmBkhKvrKTbL5NzkEp5j9PzpdeZKZWCZNK7LynZMY5kEhIJL86Skq7zO9d13lBox2WnUtu3s/u6nfNu2eLqS1m2bUqXZc6brbyn96P7ejJlm7b7NL1NKyIi/fPss1BdDfX1QUciUhyUqA7AD37wAx544AHC4TChUIj//M//5Pbbb+frX/86Bx100C5b76mnnsoDDzzA8OHDu7x+3XXXUVVVxTe+8Y1dtm4pXs3tbVx+z7/x6pstbPiwnC3rh9O2fgKpNUdCa13XiSs/gsnPQqIcPpgJzeO6lpdthqr10FED7cMhXpl9paEYlLRDOA7xCm95mSwBpdu8x7EqSEV3LA/HwIUhVeLdZ5UC828unGW6lBcDQDLCDp1ILAGhJKTC4LL8HIbi4Cx7WXrdLrTjcgEs6c2bteNKCsz1vF25zNsvfvbfr841qW7PB9oxp/tyenbI6c/z50ePG+B6ZLBrbGzkE5/4BADr168nHA4zatQoAJYsWUI0Gu1tdgAWL17MzTffzOOPP75LY5Wh7e//Hhoa4M03vQO/ItI7Jar99NJLL/H444/zpz/9idLSUhoaGojFYtxxxx27fN2LFi3a5euQwWHJEnjoIViyJMXLS41kxz90loUjcUaM28T4Y95n4sHPs+cha4hEE6xevhd/Xb43q1d8imhZnD0+tpY9DvwTY/ZdR9u2cjZ/UMumD0fSsrmSsqr1lFaupqyqnZJoApzhAJyRTISJd5SQiJWQiocpKYtTWhGjtKKDUDhFrC1KR2spHc2lYBAtjxEtjxEpjZNKGYmYN28yXkIonOq8Wchtb/Fz5rcmGi5lOGeEQq5zWsyRSoZIJcKkkiGcg3BJilBJ0it3RjIR8qZJhrquxyCVss4yM7BQilDIdcbgUoZLhXDOsFDKb830gsuMy5vXeWXm/LitcxnpssxW7M5502Uhr7xzvd3LM+YF62x97cqLrft6cObF1Vnmsrb4gmU83r4Pus67fT09y7KcPjjh6B4OiIgAtbW1rFixAtCBWylsGzZAYyNcfTXceWfQ0YgUPiWq/bRu3Trq6uooLS0FoK7Oa5GaPXs2N998M/X19dx5553cdNNNDB8+nOnTp1NaWsqtt97K/PnzKS8vZ/ny5WzYsIG77rqLe+65h5deeolZs2axcOFCAB588EF++MMf4pzj05/+NDfddBMAkydPZunSpdTV1fGDH/yAu+++m9GjRzNx4kSOOOKIQN4PKUxf/jL85S+Omr1WkZz+v3z+1Kl85ZQT2HNPGD06Qig0BhgDZHxuzum+lDrg0N0Ws4jkl5ndBXwG2OCcm5ql3ICfAqcCrcB859yfdm+Uu8btt9/OggULiMVi7Lvvvtx7771UVFQwf/58ampqWLp0KevXr+fHP/4xZ511FgDNzc2cddZZrFy5kiOOOIL77rtP5zpK3iSTsHkzjBgBd90F558Pxx8fdFQiha1oE9Ur//dKVqxfkddlHjr2UG455ZZepzn55JO5/vrr2W+//TjxxBM5++yzOe647V3SPvzwQ2644Qb+9Kc/UV1dzQknnMD06dM7yzdv3sxLL73EY489xumnn86LL77IHXfcwYwZM1ixYgWjR4/mm9/8JsuWLWPEiBGcfPLJPPLII8ydO7dzGcuWLeOhhx5ixYoVJBIJDj/8cCWq0sWGDY69j3uJN486ih+e8EO+dcwJQYckIrvfQuBW4J4eyj8FTPFvs4D/8O8HLKi6ubt58+Zx8cUXA3Dttddy5513csUVVwDeAecXXniBN998k9NPP70zUV2+fDmvv/4648eP56ijjuLFF1/k6KOPzuu2yNC1ZYs3zsE//AMsWOAdUH71VW9chmzS4yJ0H7NBZCjRx7+fqqqqWLZsGc8//zzPPvssZ599NjfeeGNn+ZIlSzjuuOMY6Z988NnPfpa33367s/y0007DzJg2bRpjxoxh2rRpABx88MGsXr2a999/n9mzZ3eeX3Peeefx3HPPdUlUn3/+ec444wwqKioAOP3003f5dkvxcA42NCT5sOUFrv741Vxz9DVBhyQiAXDOPWdmk3uZZA5wj3POAS+b2XAzG+ecW7dbAtyFVq5cybXXXsuWLVtobm7mk5/8ZGfZ3LlzCYVCHHTQQXz00Uedr8+cOZMJEyYAcOihh7J69WolqpI3DQ3efXPZ63zpH9v4zkX1nH/VXzj78tc7p0kmjL8sHcXLv5vAkqf3INYR5uOfWsPxc//KlOmbcA7ee30ES58dzxvLRlE7tpW9D97M3gduZvSEFpq3RtnSWMbWhjI62sJYyDv9JGSOaFmSsooEZRUJSiIpWpsjNG+N0rwlSiIeompYjOoRMaqHd+Cc0dIUoWVrlLaWEsIljrKKBKXlCaKlSZKJEIl4iGTCSKXSIxx6dyFzhML+LeR2mLYkkqIkmiIS8cYpiMdDJGIh4rEwoZAjEk1SEk1RUpIi0TlviFTSCJekCJc4wiXevKmkdxpPMumf/hPavt6UM1JJ//SgjLjMvJNUvFN4IOUMA68s5DDSAzh684L/HoayLNc/1SY9b8icd+pQavv7EjIHBqFQ13Ne0qcBkT4VJ2M96RjpPB1o+zxplrncbB0/XNd5dnbKzfaBKruPvNjzPDOnjeTsTxzQ+4JzVLSJan+PruZTOBxm9uzZzJ49m2nTpnH33Xf3ed50l+FQKNT5OP08kUgQiUTyHq8MLS0tkIiVsPcew7npxKvVdU1EerIHsCbj+Vr/tS6JqpldAlwCMGnSpF4XGGTdnGn+/Pk88sgjTJ8+nYULF7J48eLOssy612X8e8t8PRwOk0gkdkusMjQ0Nnr3P1j2ddj3d3DIPfxqwdn86v/egPZh0D4CtkyGtlqItMB+j0JJO79/9Cx+/8u9ofYt6KiG5vHeQIDj/gRvj+eF3+oUHQnG4WcsVqJaaN566y1CoRBTpkwBYMWKFey5556sXLkSgBkzZnDllVeyefNmqqur+dWvftXZatoXM2fO5Ktf/SoNDQ2MGDGCBx98sLO7Utqxxx7L/Pnz+da3vkUikeA3v/kNX/7yl/O3kVLU0pXh5HHVSlJFJGfOuQXAAoD6+vp+DoUVjKamJsaNG0c8Huf+++9njz32CDokGeLeeH8jMIpzZ32Sy+dcR8u8Cr55SZwtmz5NTV2KmmFJ6kYnOPakv3HU7GbKK7zTylua/8aTj9Ww6H/2oGZYkuNPWcuxn2hm2IhKYCsNG5p547Vy1n0QYURtgtpRCepGJamoTHVe2i2VNNrbjdaWEK0tIWIdRlV1iuEjkwwbniQSdWzdHGbL5jCbN4UJGVQPS1IzPElVVYpEwpu3rTVER7tREnGURByRiCMc3t5alx70z7vUm3dfUuJPG3WEDOJxI9ZhxONei2I06oiWOqJRRzIF8Y4Q8bgRj0Mk4s0fiXotlsmEkYgbiYQ3WGE47LwW1vD27UwmIeUg5F9KLhT2BzpMmXcJu9T2su6DFaZS3rzh0Pby9LzpbTLz1pdunU2ltpenB3YMhzPmzVh2979knZeVS7diuu0xGt0uh9dt8MLM5WbKHFCxp/vuMvdfttd7sveEXXelkzQlqv3U3NzMFVdcwZYtWygpKWHfffdlwYIFnee47LHHHnz7299m5syZjBw5kgMOOIBhw4b1efnjxo3jxhtv5Pjjj+8cTGnOnDldpjn88MM5++yzmT59OqNHj2bGjBl53UYpbms/agPKGTd655dkEJEh7QNgYsbzCf5rRe+GG25g1qxZjBo1ilmzZtHU1BR0SDLEvfDmG8Ao5n/sM3xs4n4wEZa9lG3KEV2fjoaZV8I/Xpl+YdgO5cftMFSayOBgrr/XCdhN6uvr3dKlS7u89sYbb3DggQcGFFHfNTc3U1VVRSKR4IwzzuCiiy7ijDPOCDos2UUK7XN5z6/X8fkzx/HN2xdx45dODTockYJhZsucc/VBx7E7+eeoPt7DqL+fBi7HG/V3FvAz59zM3pZXzHWzDC2F9rmcfsH9vHrfeTQ1Oaqq1NtJJK23ulktqrvAddddx9NPP017ezsnn3xyl4GQRHa11eu2AePYa4+aoEMRkQCZ2YPAbKDOzNYC3wMiAM6524BFeEnqKrzL03whmEhFBreUS/HO2kZCkRiVlertJNJXSlR3gZtvvjnoEGQIW7O+DYB99hgecCQiEiTn3A5XR+5W7oC/303hiAxZK9avoG1rJSNGxDFToirSV6GgAxCR/Fr3UQcA+08YFXAkIiIi8rt3fwetdYwfoyRVpD+UqIoMMhsaUlC6lfHD64IORUREZMh76r2nqEhMZMwoXYJQpD+UqIoMMps2GeHKLYRD4aBDERERGdJa46288LcXKO2YQJ2OH4v0ixJVkUFm2+YSSqubgw5DRERkyHv+/eeJJWMkW4YrURXpJyWq/RQOhzn00EOZOnUqn/3sZ2ltbe1x2oULF3L55Zfvxui2++53v8vTTz/d6zTz58/nl7/85W6KqP9uu+027rnnnrws64c//GGX5x//+MfzstxC1LK1nIqatqDDEBHZbVQ37z6qm/vnqfeeImJlNG2JKFEV6Sclqv1UXl7OihUrWLlyJdFolNtuuy3okLK6/vrrOfHEE4MOo5NzjlQq1a95Lr30Ui688MK8rL97ZfiHP/whL8stRB1NVdSMSAQdhojIbqO6eWBUN+96v3v3dxxZdwrOGbW1QUcjUlzykqia2Slm9paZrTKza3qZ7kwzc2Y2KC64fswxx7Bq1So2bdrE3LlzOeSQQzjyyCN59dVXu0zX1NTEXnvtRTweB2Dbtm2dz2fPns03v/lNZs6cyX777cfzzz8PQHt7O1/4wheYNm0ahx12GM8++yzgHQmeO3cuJ510EpMnT+bWW2/lJz/5CYcddhhHHnkkmzZtAroekb3++uuZMWMGU6dO5ZJLLsG7IkHPbr/9dmbMmMH06dM588wzO49Mz58/n0svvZT6+nr2228/Hn/88c6Y5syZw+zZs5kyZQrf//73AVi9ejX7778/F154IVOnTmXNmjVcffXVTJ06lWnTpvHwww8D8LWvfY3rr78egCeffJJjjz2WVCrFdddd13mpn9mzZ3PVVVdRX1/PgQceyCuvvMK8efOYMmUK1157bWfsc+fO5YgjjuDggw9mwYIFAFxzzTW0tbVx6KGHct555wFQVVUFeJV0tpgWL17M7NmzOeusszjggAM477zzdvq+FYJkKkmyZTgjR/bvj4eIyGChull1c6FY37ye1za8xozhnwJQi6pIP+V8HVUzCwM/B04C1gKvmNljzrm/dJuuGvga8Mdc1wlw5ZWwYkU+lrMUBdQAACAASURBVLTdoYfCLbf0bdpEIsETTzzBKaecwve+9z0OO+wwHnnkEZ555hkuvPBCVmQEV11dzezZs/ntb3/L3Llzeeihh5g3bx6RSKRzWUuWLGHRokV8//vf5+mnn+bnP/85ZsZrr73Gm2++ycknn8zbb78NwMqVK1m+fDnt7e3su+++3HTTTSxfvpyrrrqKe+65hyuvvLJLrJdffjnf/e53Abjgggt4/PHHOe2003rctnnz5nHxxRcDcO2113LnnXdyxRVXAF4Ft2TJEt59912OP/54Vq1aBcCSJUtYuXIlFRUVzJgxg09/+tPU1dXxzjvvcPfdd3PkkUfyq1/9ihUrVvDnP/+ZhoYGZsyYwbHHHsuPfvQjZsyYwTHHHMNXv/pVFi1aRCi04zGUaDTK0qVL+elPf8qcOXNYtmwZI0eOZJ999uGqq66itraWu+66i5EjR9LW1saMGTM488wzufHGG7n11lu77JO0X//611ljAli+fDmvv/4648eP56ijjuLFF1/k6KOP7tsHJCDrtzVCx2hGjdJASiKy+6luVt2sunm7p9/zunkfVOnFrkRVpH/y0aI6E1jlnHvPORcDHgLmZJnuBuAmoD0P6wxM+uhffX09kyZN4otf/CIvvPACF1xwAQAnnHACjY2NbNu2rct8X/rSl/jFL34BwC9+8Qu+8IUvdJbNmzcPgCOOOILVq1cD8MILL3D++ecDcMABB7Dnnnt2VobHH3881dXVjBo1imHDhnVWbNOmTeucP9Ozzz7LrFmzmDZtGs888wyvv/56r9u4cuVKjjnmGKZNm8b999/fZfrPfe5zhEIhpkyZwt57782bb74JwEknnURtbS3l5eXMmzePF154AYA999yTI488snObzjnnHMLhMGPGjOG4447jlVdeoaKigttvv52TTjqJyy+/nH322SdrXKeffnrndh588MGMGzeO0tJS9t57b9asWQPAz372M6ZPn86RRx7JmjVreOedd3rd1p5iApg5cyYTJkwgFApx6KGHZn1vC81bazYCMG6UrtUmIkOH6mbVzYVo+brllJWUUct+AOr6K9JPObeoAnsAazKerwVmZU5gZocDE51zvzWzq3takJldAlwCMGnSpF5X2tejq/mWPg+mv4466ihWr17N4sWLSSaTTJ06tbOstLQU8AaDSCR2fm5henqAUCjU+TwUCu0wf3t7O5dddhlLly5l4sSJXHfddbS3936sYP78+TzyyCNMnz6dhQsXsnjx4s4yM+sybfp5T69XVlbudHsAXnvtNWpra/nwww97nCZzO7u/B4lEgsWLF/P000/z0ksvUVFRwezZs3e6rb3JXEdf903QVq3dDMDEsRUBRyIiQ5HqZo/qZtXNAB3JDioiFWxq9NqF1KIq0j+7fDAlMwsBPwH+386mdc4tcM7VO+fqR40atatDy5tjjjmG+++/H/DOn6irq6OmpmaH6S688ELOPffcLkds+7LMt99+m7/97W/sv//+/Y4tXRnU1dXR3Nzcp5EEm5qaGDduHPF4vDOGtP/+7/8mlUrx7rvv8t5773XG9NRTT7Fp0yba2tp45JFHOOqoo7Ju08MPP0wymWTjxo0899xzzJw5k/fff59/+Zd/Yfny5TzxxBP88Y8D6x2+detWRowYQUVFBW+++SYvv/xyZ1kkEuk8D6kvMRWr1eu81oLJ46sDjkREJFiqm1U3By2WjBENR2lo8J4rURXpn3y0qH4ATMx4PsF/La0amAos9o/kjQUeM7PTnXNL87D+wF133XVcdNFFHHLIIVRUVHD33Xdnne68887j2muv5ZxzztnpMi+77DK+8pWvMG3aNEpKSli4cGGXo4h9NXz4cC6++GKmTp3K2LFjmTFjxk7nueGGG5g1axajRo1i1qxZNDU1dZZNmjSJmTNnsm3bNm677TbKysoAryvOmWeeydq1azn//POpr6/foTvOGWecwUsvvcT06dMxM3784x8zZswYTjrpJG6++WbGjx/PnXfeyfz58zu7+PTHKaecwm233caBBx7I/vvv39mtCeCSSy7hkEMO4fDDD+9SwWeLaezYsZ3dporNmvXeZWmmTBgRcCQiIsFS3ay6OWidiepHUFYGFersJNIvlutoaWZWArwNfAIvQX0FONc5l/VkCzNbDHxjZ0lqfX29W7q06yRvvPEGBx54YE7xBumXv/wljz76KPfee2/QoQzI/Pnz+cxnPsNZZ53V5fWFCxeydOlSbr311oAiC1YhfS5PvOpBfn/LOaxeDXvuGXQ0IoXFzJY55wbFqPNBUd1ceFQ3Z1cIn8tzf3Uur3z4CseueIcnn4S1awMNR6Qg9VY359yi6pxLmNnlwJNAGLjLOfe6mV0PLHXOPZbrOgaDK664gieeeIJFixYFHYoMYhsbvMvSaMAGEZGdU90su1Jm1191+xXpv5xbVHeVwXjUVganQvpcTjz1QT546kySsSjdxtAQGfLUopo71c1SLArhc3n6g6ezZtsaKu5ZTnk5PP10oOGIFKTe6uZdPphSvhVqYi1DU6F9HrdtLqG0ullJqojsVoX2WyhDW6F8HtMtqo2N6ukkMhBFlaiWlZXR2NhYMD9AMrQ552hsbOwctKIQtG4tp3JYUV+qWESKjOpmKSSFVDer669IbvIx6u9uM2HCBNauXcvGjRuDDkUE8P6gTZgwIegwAGiJtZBoGUbNyMK9ppyIDD6qm6XQFErdHEvGiIbK2bRJiarIQBRVohqJRNhrr72CDkOkIK1vXg+ttYzcV60aIrL7qG4WyS6WjFEa2wPnlKiKDERRdf0VkZ6ta14HbbWMHqWvtYiISNBiyRi0eien6hxVkf7TP1qRQWJd03poG8n4Mf2/+LyIiIjkVywZI9UyElCLqshAKFEVGST+ur4RUhEmji0POhQREZEhT4mqSG6UqIoMEqs/bAJg4tjKgCMRERGReCpOsmU4oERVZCCUqIoMEms+agVgVJ2+1iIiIkGLJWPEm4YBOkdVZCD0j1ZkkFi/wbssjSpDERGR4MWSMeLNwygrg4qKoKMRKT5KVEUGiQ0NSUCJqoiISCGIJWPEmmqoqwOzoKMRKT5KVEUGic2bvK+zElUREZHgxZIxOpqqVC+LDJASVZFBIJlK0rQlCpZixIigoxERERnanHPEkjHat1VpICWRAVKiKjIIbGzdCK0jqaiOEQ4HHY2IiMjQlkh540a0b6tUoioyQEpURQaB9c3robWWmuGJoEMREREZ8mLJGACt28qVqIoMkBJVkUFgXdM6aKults4FHYqIiMiQF0vGIBWibVu5zlEVGSAlqiKDQLpFdbSuoSoiIhK4WDIGbSNwztSiKjJA+lcrMgisa/ZaVMeNLg06FBERkSEvloxBq5ehKlEVGRglqiKDwKa2TdBWy5hRJUGHIiIiMuR5Lapen191/RUZGCWqIoNAc2sCYrpWm4iISCFQi6pI7pSoigwCWzZ516RRoioiIhI8JaoiuVOiKjIIbN3sdflVoioiIhI8L1H1KmUlqiIDo0RVZBBo3uoNoqREVUREJHjpc1Qj0SQVFUFHI1KclKiKDAJKVEWkOzM7xczeMrNVZnZNlvL5ZrbRzFb4ty8FEafIYBRLxiBWRXllKuhQRIqWhggVGQRatpQBSlRFxGNmYeDnwEnAWuAVM3vMOfeXbpM+7Jy7fLcHKDLIxZIxiJdTXq5EVWSg1KIqMgi0bfP6FSlRFRHfTGCVc+4951wMeAiYE3BMIkNGLBmDRDmlZS7oUESKlhJVkUGgo6WMUCRGeXnQkYhIgdgDWJPxfK3/WndnmtmrZvZLM5uYbUFmdomZLTWzpRs3btwVsYoMOl6LagXlFUpURQZKiarIIBBri1JS1h50GCJSXH4DTHbOHQI8BdydbSLn3ALnXL1zrn7UqFG7NUCRYrW9668SVZGBUqIqMgjEOyJESuNBhyEiheMDILOFdIL/WifnXKNzrsN/egdwxG6KTWTQ62xRLbegQxEpWkpURQaBREeUSJkSVRHp9Aowxcz2MrMo8HfAY5kTmNm4jKenA2/sxvhEBrX0OaqVujSNyIDlJVHtwxD4Xzezv/jnwfzezPbMx3pFxJPsiBItTQQdhogUCOdcArgceBIvAf0v59zrZna9mZ3uT/ZVM3vdzP4MfBWYH0y0IoNPukW1Qi2qIgOW8+Vp+jgE/nKg3jnXamZfAX4MnJ3rukXEk4yVEa1Qoioi2znnFgGLur323YzH3wK+tbvjEhkK0ueoVlaq86LIQOXj27PTIfCdc88651r9py/jnSsjInkQT8YhVkGprtUmIiJSENItqpUValEVGah8JKp9HQI/7YvAE3lYr4gAbYk2iFdQVpEMOhQRERFh+zmqVZXhoEMRKVo5d/3tDzM7H6gHjuuh/BLgEoBJkybtxshEild7ot0fWVAtqiIiIoWgI+F1/dU5qiIDl48W1Z0OgQ9gZicC3wFOzxgOvwtdq02k/9ribbqouIiISAFp70iCK6GyUomqyEDlI1HtyxD4hwH/iZekbsjDOkXEl+76W1EedCQiIiIC0NrmHTwuV90sMmA5J6p9HAL/n4Eq4L/NbIWZPdbD4kSkn7yuv5W6VpuIiEiBaPWHEK1Q3SwyYHk5R7UPQ+CfmI/1iMiOmlrbIRWhqkrdi0RERApBW5t3rxZVkYHTxZ1EitzmJu+Ub12rTUREpDC0tXkHj5Woigyc/tmKFLmtTXEAqjUEvoiISEFob/cSVXX9FRk4JaoiRW5bcwKAmiolqiIiIoWgvc37i60WVZGBU6IqUuS2tXiJanXVbr0ssoiIiPSgo937i60WVZGBU6IqUuS2NSUBGF4dCTgSERERAeho83o5qUVVZOCUqIoUueaWFADDlKiKiIgUhFi7l6iqRVVk4JSoihS5dKI6vDoacCQiIiICEOtQi6pIrpSoihS5dKI6oro04EhEREQEINbujRuhFlWRgVOiKlLkWlu9+2qN+isiIlIQ4h1eoqoWVZGBU6IqUuRaW71rtVVWBhyIiIiIABDv8MaNKCsLOBCRIqZEVaTItbXqouIiIiKFJNkRIRztwCzoSESKlxJVkSLX3q6LiouIiBSSREeUktJ40GGIFDUlqiJFrr01hJV0ENYpqiIiIgUhEYtSUhoLOgyRoqZEVaTIdbSHCEXbgw5DREREfMlYKZFoIugwRIqaElWRItfRFiFc2hF0GCIiIuJLxaJEytT1VyQXSlRFily8vUSJqoiISAFJxcqIlCaDDkOkqClRFSly8Y4IEZ0HIyIiUhCcc7h4GaVl6vorkgslqiJFLtERJaKRBUVERApCPBWHeDnRMrWoiuRCiapIkUt0RInoqK2IiEhBiCVjEK+gtDwVdCgiRU2JqkiRS8ZKiSpRFRERKQixZAwS5ZSWKVEVyYUSVZEil+oop6xciaqIiEghSLeolilRFcmJElWRIpeKlal7kYiISIHwEtVyyspd0KGIFDUlqiJFLOVSEK+gXImqiIhIQUi3qJYrURXJiRJVkSLWkejwKsMKVYYiIiKFoKU9Bq6E8vKgIxEpbkpURYpYU3sbJEtVGYqIiBSIbc3euBHlFQEHIlLklKiKFLFNW9sBqKwMOBAREREBoLnFu35qZYUFHIlIcVOiKlLEtjTFAKisVGUoIiJSCJpavBbVinLVzSK5UKIqUsQ2N3UAUFWpr7KIiEghaG7xBjjUQWSR3OjfrUgR29oUB5SoioiIFIrm1nTXX9XNIrnQN0ikiG1t9hLVmqpwwJGIiIgIQIvfoqqDyCK50TdIpIhtbfLOg6mpjAQciYiIiAC0tHqXjKuq0EFkkVzkJVE1s1PM7C0zW2Vm12QpLzWzh/3yP5rZ5HysV2Soa2r2uhfVVKsyFJGuVDeLBCOdqFZXlgQciUhxyzlRNbMw8HPgU8BBwDlmdlC3yb4IbHbO7Qv8K3BTrusVEWjyh8AfXh0NOBIRKSSqm0WC09rmJ6o6LUckJ/loUZ0JrHLOveeciwEPAXO6TTMHuNt//EvgE2amodBEcpQeWVCJqoh0o7pZJCBtrd69WlRFcpOPRHUPYE3G87X+a1mncc4lgK1AbfcFmdklZrbUzJZu3LgxD6GJDG4tLd5RWyWqItKN6maRgLS1ecd7hlVp/AiRXBTUYErOuQXOuXrnXP2oUaOCDkek4DX758GMqCkNOBIRGaxUN4v0T1url6jWKFEVyUk+EtUPgIkZzyf4r2WdxsxKgGFAYx7WLTKkpSvD2prygCMRkQKjulkkIO3tfqJaqd5OIrnIR6L6CjDFzPYysyjwd8Bj3aZ5DPi8//gs4BnnnMvDukWGtLZWINxBRakqQxHpQnWzSEDa2w1K2igtUYuqSC5yPsvbOZcws8uBJ4EwcJdz7nUzux5Y6px7DLgTuNfMVgGb8CpMEclRW5tBpBUzdf0Vke1UN4sEp6MtBJFWwiH1dhLJRV6GI3POLQIWdXvtuxmP24HP5mNdIrJde1sYi7YHHYaIFCDVzSLB6GgPQ0R1s0iuCmowJRHpn462ECElqiIiIgWjoz1MKNIWdBgiRU+JqkgR62grIVyqylBERKRQxNvV20kkH5SoihSxWEeEcDQWdBgiIiLii7WXEIqobhbJlRJVkSIWby+hpFSVoYiISKGIx0oIl6pFVSRXSlRFiliiI0qkLB50GCIiIuKLt0cIq0VVJGdKVEWKWKIjSrRUiaqIiEihSMQihNXbSSRnSlRFiliyo4xoeSLoMERERMSX6IjqtByRPFCiKlLEkrFSomVKVEVERApFMhalRL2dRHKmRFWkiKViZZSVp4IOQ0RERHzJWJSIElWRnClRFSlSySSQUKIqIiJSSFKxMiKl6u0kkislqiJFqq3Nuy8vd8EGIiIiIgDE4+CSJUSVqIrkTImqSJFqafHuyyuUqIqIiBSC9EHkSFky2EBEBgElqiJFamuTd/5LZWXAgYiIiAiwPVEtVaIqkjMlqiJFanNTBwCVFRZwJCIiIgLQ2urdl5Zp/AiRXClRFSlSW5q8a7RVVipRFRERKQRqURXJHyWqIkUqnahWV4YDjkRERERge4tqmQY6FMmZElWRIpU+R7WqUl9jERGRQqAR+UXyR/9wRYrU1iZv6Pth1SUBRyIiIiKQ0aJapkRVJFdKVEWKVFOzl6jWVClRFRERKQTpFtWKimDjEBkMlKiKFKmmFm+ghmHVkYAjEREREYCWVm+03/LygAMRGQSUqIoUqaYWrzIcXhUNOBIREREBaGr2DiKrRVUkd0pURYpUS4t3/svwGiWqIiIihaC51UtUKyv0F1skV/oWiRSp5hYHoRjV5WVBhyIiIiJktqjqGuciuVKiKlKkWluBSCvlJToRRkREpBCkz1FVi6pI7vQtEilSba3mJaoRJaoiIiKFoLklBeF2yiI6LUckV0pURYpUW5uXqJaVqOuviIhIIWhtcxBpJRpWoiqSKyWqIkWq3U9U1fVXRESkMLS0OIi0KVEVyQMlqiJFqr21BIu2EQ6Fgw5FREREgDa1qIrkjRJVkSLV0R4mFG0LOgwRERHxtbYCJWpRFckHJaoiRSrWXkK4NBZ0GCIiIuJra0MtqiJ5klOiamYjzewpM3vHvx+RZZpDzewlM3vdzF41s7NzWaeIeOIdJZQoURURESkY7e2mc1RF8iTXFtVrgN8756YAv/efd9cKXOicOxg4BbjFzIbnuF6RIS/eHiWiRFVERKRgpC8dp0RVJHe5JqpzgLv9x3cDc7tP4Jx72zn3jv/4Q2ADMCrH9YoMeYmOKJGyeNBhiIiIiK+jPaRzVEXyJNdEdYxzbp3/eD0wpreJzWwmEAXe7aH8EjNbamZLN27cmGNoIoNbsqOUqBJVERGRgtHeHlLXX5E8KdnZBGb2NDA2S9F3Mp8455yZuV6WMw64F/i8cy6VbRrn3AJgAUB9fX2PyxIZ6lIpSMVLiZYngw5FREREfB3tYXX9FcmTnSaqzrkTeyozs4/MbJxzbp2fiG7oYboa4LfAd5xzLw84WhEB/FEFgdIyJaoiIiKFItYeVtdfkTzJtevvY8Dn/cefBx7tPoGZRYH/Ae5xzv0yx/WJCP512oCy8qydE0RERCQAMbWoiuRNronqjcBJZvYOcKL/HDOrN7M7/Gk+BxwLzDezFf7t0BzXKzKkpRPV8gr1kBcRESkEiQQkE2GdoyqSJzvt+tsb51wj8Iksry8FvuQ/vg+4L5f1iEhXLS3efblaVEWkGzMbCTwMTAZWA59zzm3OMl0SeM1/+jfn3Om7K0aRwSh9Wo5aVEXyI9cWVREJQLpFtbLSgg1ERApRX65xDtDmnDvUvylJFclRZ6Kqc1RF8kKJqkgRSieqFeVKVEVkBzu9xrmI5F+6bibSSiQcCTQWkcFAiapIEdq02evyWzNMXX9FZAd9vcZ5mX/t8pfNrMdkVtc4F+mbdItqKBojZPqLLZKrnM5RFZFgfLQxAUQZMVKJqshQlKdrnO/pnPvAzPYGnjGz15xz73afSNc4F+mbdItqSWks2EBEBgklqiJFaP0GL1GtrQ06EhEJQj6uce6c+8C/f8/MFgOHATskqiLSN+kW1UhpIthARAYJ9UsQKUIbNiYhFGdYjb7CIrKDvlzjfISZlfqP64CjgL/stghFBqH0iPzRsniwgYgMEvqXK1KEGhpTUN5IRbQ86FBEpPD05RrnBwJLzezPwLPAjc45JaoiOdi0ybuPVrUEG4jIIKGuvyJFqLERqGikvESJqoh01cdrnP8BmLabQxMZ1BoavPuymuZgAxEZJNSiKlKENjUaVDRQVlIWdCgiIiKCn6hairLqtp1OKyI7p0RVpAht2RyG8kbKI2pRFRERKQQNDRCtaqY0og6LIvmgRFWkCG3ZHIaKRoaVDgs6FBEREcE7LSdStY1oOBp0KCKDghJVkSLjHGzbHIHyRsZVjws6HBEREcFrUS2p2qpEVSRPlKiKFJnmZkgmvBbV0ZWjgw5HRERE8BPVys1KVEXyRImqSJFpbPTuq4bHVBmKiIgUiMZGCFVuUd0skidKVEWKTHr4+5EjXbCBiIiICOCdltPQAKHKTUpURfJEiapIkUm3qI6uCwcbiIiIiADQ2grt7WAVjUpURfJEiapIkUknquPHlAYbiIiIiADbeztRsVGJqkieKFEVKTINDV6X30ljKwKORERERGD7QeRUeYMSVZE8UaIqUmQ++KgdgD3H1gQciYiIiMD2FtVU+QaiISWqIvmgRFWkyKz9qA3KNrPH8DFBhyIiIiJsT1STZR8RCUeCDUZkkCgJOgAR6Z91G2JQ3sy46nFBhyIiIiJsT1QTZR+p669InqhFVaTINDSkoKKRsVVjgw5FRERE8M5RNYN4dIMSVZE8UaIqUmQ2bwpBeSPjqtSiKiIiUggaGmDkSIi7diWqInmiRFWkyGzbEiVUuYWaUg2mJCIiUggaGqCuzpF0SSWqInmiRFWkyLRuLadqWAdmFnQoIiIigpeojhjpXT5OiapIfihRFSkisRgk2ssZNjIedCgiIiLia2yEkbVJQImqSL4oURUpIukLitfWBhuHiIiIbNfQAMNHKlEVySclqiJFJJ2ojq4LBxuIiIiIAOCcl6gOG5EAlKiK5IsSVZEism5DDIDxY0oDjkREREQAWlqgowNqRnh1tBJVkfxQoipSRN77YAsAE8dWBByJiIiIwPbeTkpURfIrp0TVzEaa2VNm9o5/P6KXaWvMbK2Z3ZrLOkWGstXrmgHYe/ywgCMRERER8Lr9AlQP7wCUqIrkS64tqtcAv3fOTQF+7z/vyQ3AczmuT2RIW/tRGwBTJvR4TEhERER2o3SiWjmsHVCiKpIvuSaqc4C7/cd3A3OzTWRmRwBjgN/luD6RIW39hjiUtLHX6LFBhyIiIiJkJKrDvYPJSlRF8iPXRHWMc26d/3g9XjLahZmFgH8BvpHjukSGvIYGBxUNjKoYFXQoIiIiwvZzVCuGtQJKVEXypWRnE5jZ00C25pvvZD5xzjkzc1mmuwxY5Jxba2Y7W9clwCUAkyZN2lloIkPOpk0hwpVbiYQnBh2KiIiI4LWomkFJhTeOhBJVkfzYaaLqnDuxpzIz+8jMxjnn1pnZOGBDlsk+BhxjZpcBVUDUzJqdczucz+qcWwAsAKivr8+W9IoMaU1bopTXbAs6DBEREfE1NMDIkbD8o6UATBk5JeCIRAaHXLv+PgZ83n/8eeDR7hM4585zzk1yzk3G6/57T7YkVUR2rm1rOZXDOoIOQ0RERHyNjVBXB0+99xTTx0xnTNUOZ8KJyADkmqjeCJxkZu8AJ/rPMbN6M7sj1+BEpKtYczXDRiSCDkNERER8DQ0wsjbJi397kZP2PinocEQGjZ12/e2Nc64R+ESW15cCX8ry+kJgYS7rFBmqkklHqnU4tbVBRyIiIiJpDQ1QMaqBeCrOyfucHHQ4IoNGri2qIrKbrF6/GVyYMXU5HV8SERGRPGpogKbwXykNl3L0pKODDkdk0FCiKlIk3lrrXaht/JjSgCMRERERAOe8c1TXu9c5Zs9jKI+UBx2SyKChphmRIvHuB1sAmDSuMuBIREREBKClBTo6oMO9pfNTRfJMLaoiReL9D1sA2HuPmoAjEREREfC6/QJQ0aBEVSTPlKiKFIm169sAmDJhZMCRiIiICGxPVGtGxJk+dnqwwYgMMkpURYrE+o1xACaNVddfERGRQtDQ4ACYOWVvQqa/1SL5pG+USJFoaEyBJRk+3IIORUQKmJl91sxeN7OUmdX3Mt0pZvaWma0ys2t2Z4wig8Xy99YAcPxBhwQcicjgo0RVpEhs3hSmpHIbIX1rRaR3K4F5wHM9TWBmYeDnwKeAg4BzzOyg3ROeyODxx7dXAXDaYR8LOBKRwUej/ooUiaYtEcprWoERQYciIgXMOfcGgFmvvS9mAqucc+/50z4EzAH+sssDBGLxVL/nMfNu6cdpzvV+n205Kjg5yAAADwdJREFUoVDX5WXOk0p59871PG361l3mtOllpW+hEITDXcuTSe+WXk/6ll5+Mundp19Pz5u53Mx5M9ebnjcc3r5e2F6WSHjzlJR45eltSyYhFvOmi0YhEum67R3/v727j5Gjvu84/v7O7u3d2ednjG3AD7h1Ao7bALEANW0hFAFBDZCUUreiAUrDQ9OoUlW1RChRglQ1VKoi0SIRimhIWpEHtyhueKrNQx6kOCTiyTzE4IfS4Ccg+AH77vZ2Z779Y2bPc+td3x7em529+7yk0c7+Hma++9vx/u6389ufy3F+sRjnF1N/SYYhVCrxY+246XOny42MxGWjCGbOjM+Tzj90CA4ehL4+WLBgbH61Cu++C0NDMDAQb6XSseepVODtt2HvXhgchNWrYX5qmYehIdi0CR571Dj1VOdPPw1Ll46t/4MfwI9/ZOzfD/sPwIEDcNnHQ667cYiRcIQXdu4GC1m99JTGF5yIvG8aqIp0gXK1zOChGSycU+50KCIyNZwK/DL1/E3gvKxOPnPxLqrvLh2/oLRRBObghcZ5QRWiIg0n2xXK4AZR6dg8CyGoQNTT5Nh154HG5whGoHQkPk959rFleg/GW3lOvB1TvwKFEbAo3qBxubk7YMmz8WvdfglUZ0DPYagM8IUvRLByE5z5X7B7LfziKhg6KY677yD0HQA3Hv7+Mj737CWwdDPsvpu+WUMUCgPjvHYRmSgNVEVyLoxCrn3oWsLDt7Ns9YxOhyMiOWBmm4DFDbJud/fvtflcNwE3ASxbtqwtx7zy+u3sP7Ct5fIO8QCGxncyR++kWZw5emPN6gq7jR7Lo3i/vqwFHqclz71W1m003Sx5bBDjaFnz+FhBFN/pTNKjyMAtTg+cIEjOE8V5HgVH65ong0sbG0cQxfXqY6zVLUTxoxEfMwxGzxsUQ4JCXN+BqFogrAZEYUChGFEohhR6QjAnqhaoVgqEI0Uwp9gTUihVKRRDPApG88IwiOsl9S1wosiIwgAPg2Pev0JPSKEQjZ6nMtzDyFCJynB827Rv1jD9A8P0zixTHSkyeHAGg4f6KR/ppXfmHvpnDTFj9hDF3gqV4RIjQ/EWVgpxW3jcJv2zhhiYd4SB+YcplkL2bj+ZPa8vYc/Wi4gi4wO//xJn/PZrLP/w//LeO7N5/rEP89xj53Lw4UvonVHmgx/dyuoLnuDXz91OT28VgPJgibuvv5X+pzbwtw98h//48WUcXNw3/kUsIhOmgapIjrk7N3//Zta/sp65fj8fWjGr0yGJSA64+8UneIhdQPqW5mlJWqNz3QvcC7B27domE2onZv0/XdiOw4icoHOTLbEunor8yiuwalUvvb2/CRy7SNL598EVV8DQDz/L7BD6FmYWsMi0ooGqSA65w969zl898K98d9NCzhh5idfemcWCBZ2OTESmiJ8Bq8zsdOIB6jrgTzobkkjnBQGsWXP8Mp/4BFx9NdxxB8ydC+efn01sItPNlB+ofvGeZ9h/MBybWD8VqIGjCzYcLes+9lf6o9OP6tLT52l0nNqx3OvqJuUtNZVnzHnq4quPLZ4SlOQlU4aOLqwQ50Mt72j92nSg+rrpONN1a9OUanVr5w0CCApRasEGIwrjqUxmTlBwCoX4MQqNsBoQhpYs9uDJlKH42GHVqFbiqUgWxHnFYnS0bhgQVo9Or6qdO90+tRjCajz9KHIolSJ6ekN6SiEOlAeLDA8VKQ8WKfZE9A9U6B+o0NsXUh4uMHS4h+EjPVRGAnp6Q0rJVijGU65qK/AODxY58l4PRw6VqJQLnLRkkEVL32PxssO4w7YtC9i2ZQE7Xp7PwJwR1py3jzXn7WPRskMcPtTD1ucWsPW5hex8dQ5v7ZrB/r2zCSs9JLPtqPyac801cMMNjS81EZEaM/sk8M/AQuBhM3ve3S81s1OA+9z9cnevmtlfAo8DBeB+d3+5g2GLdJW77oKNG2HfPvQlssgkmfID1a988WQqb6/odBgi8WIUi16EXyzimY3Jf23Y/06yUAPxQhCLXoR5Oyit2MP8RQf4nXNO5ms33cRJC/R/0ohIa9z9IeChBum7gctTzx8BHskwNJEpY8kSuPNOuOUWDVRFJsuUH6j+z+PG0Mj2ownN7n6mHG9p+/qlz+sXcEifJ32c2t3K+rq1BRkY/fH/2LLNluKvLxsERxeAcGqLMsS/tSgU4vzRGN3GLJc/ehe1rm56SfxmdeP6R+++1vJqS+IHBacQ1Ja8N8IQotAICk6xCMXkDmo1rN1FNcygUHSKxbhMFEG1alSrcZlCkl4ojL1jHIbHvn+1csVi/BpGRoyR4YByOW7QGTMjZsyM6O93KhXjyOGAw+8FDA0G9PVHzByIt1Iprjs8ZJSHA6pVRl+ze3yc2XNCZs+J7wrv3dXDGzt7+L+dJaIQ1pw9zJlrypR6Z+E+yBs7trP5RzPZ8mwfy1e+w0fOG+ascyrMHjiZhTM/RF9RCzOIiIjk2Wc+A7t3w6c+1elIRKamKT9QvfDs5Z0OQaahNYuBjzTPP3MhXJbZfwQhIiIi7RYE8OUvdzoKkalL8wlFREREREQkVzRQFRERERERkVzRQFVERERERERyRQNVERERERERyRUNVEVERERERCRXNFAVERERERGRXNFAVURERERERHJFA1URERERERHJFXP3TsfQkJm9DbzRpsOdBLzTpmNlSXFnS3Fnq1vjhu6NfbrHvdzdF7bhONOW+mZAcWdNcWerW+OG7o19usfdtG/O7UC1nczs5+6+ttNxTJTizpbizla3xg3dG7viljzp1vdVcWdLcWerW+OG7o1dcTenqb8iIiIiIiKSKxqoioiIiIiISK5Ml4HqvZ0O4H1S3NlS3Nnq1rihe2NX3JIn3fq+Ku5sKe5sdWvc0L2xK+4mpsVvVEVERERERKR7TJc7qiIiIiIiItIlpsxA1cz+0MxeNrPIzJquQGVml5nZVjPbZma3pdJPN7OfJunfNrNSRnHPN7ONZvZ68jivQZmPmdnzqW3YzK5K8r5uZjtTeWflJe6kXJiKbUMqPc/tfZaZ/SS5nl40sz9K5WXa3s2u11R+b9J+25L2XJHK+3ySvtXMLp3MON9H3H9tZq8k7fuEmS1P5TW8ZnIS9/Vm9nYqvj9P5V2XXFevm9l1OYv7q6mYXzOzA6m8Trb3/Wb2lpm91CTfzOyu5HW9aGbnpPI61t7SOvXN6pvbFbf65kziVt+cbdzqm8fj7lNiA84EPgg8DaxtUqYAbAdWAiXgBWB1kvcdYF2yfw9wa0Zx/yNwW7J/G3DnOOXnA+8CM5LnXweu7kB7txQ3cLhJem7bG/gAsCrZPwXYA8zNur2Pd72myvwFcE+yvw74drK/OinfC5yeHKeQo7g/lrqGb63FfbxrJidxXw/8S4O684EdyeO8ZH9eXuKuK/854P5Ot3dy7t8FzgFeapJ/OfAoYMD5wE873d7aJvweq2/Otr3VN09+rOqbM9xajPt61De3M/bc9M1T5o6qu7/q7lvHKXYusM3dd7j7CPAt4EozM+AiYH1S7gHgqsmLdowrk/O1et6rgUfdfXBSoxrfROMelff2dvfX3P31ZH838BbQ8D8inmQNr9e6MunXsx74vaR9rwS+5e5ld98JbEuOl4u43f2p1DW8GTgto9iOp5X2buZSYKO7v+vu+4GNwGWTFGe9icb9x8CDmUQ2Dnf/IfEf981cCXzDY5uBuWa2hM62t0yA+ubMqW+efOqbs6W+OWN56punzEC1RacCv0w9fzNJWwAccPdqXXoWFrn7nmR/L7BonPLrOPZC/vvk1vtXzay37RE21mrcfWb2czPbXJsSRRe1t5mdS/xN2PZUclbt3ex6bVgmac+DxO3bSt3JMtFz30j8zVxNo2smC63G/QfJ+7/ezJZOsO5kaPncyTSu04EnU8mdau9WNHttnWxvaT/1ze2jvll9czPqm3Pa3uqbmyueSOWsmdkmYHGDrNvd/XtZx9Oq48WdfuLubmZNl2FOvq34DeDxVPLniT/US8TLRP8dcMeJxpycrx1xL3f3XWa2EnjSzLYQf2BPmja39zeB69w9SpInrb2nIzO7FlgLXJBKPuaacfftjY+Quf8GHnT3spndTPyN+UUdjmki1gHr3T1MpeW5vaULqG9W39wK9c3dQ31z5tQ3N9FVA1V3v/gED7ELWJp6flqS9ivi29bF5JuvWnpbHC9uM9tnZkvcfU/y4fvWcQ51DfCQu1dSx659A1k2s38D/qYtQdOeuN19V/K4w8yeBs4G/pOct7eZzQYeJv5Da3Pq2JPW3g00u14blXnTzIrAHOLruZW6k6Wlc5vZxcR/oFzg7uVaepNrJosP53HjdvdfpZ7eR/y7qlrdC+vqPt32CBubyHu9DvhsOqGD7d2KZq+tk+0tddQ3q2/OKm71zSdEfbP65nbJrG+eblN/fwassnhVuxLxhbHB3R14ivg3JgDXAVl9C7whOV8r5z1m/nrygV77bclVQMMVuibBuHGb2bza9BszOwn4KPBK3ts7uTYeIp5/v74uL8v2bni91pVJv56rgSeT9t0ArLN45cHTgVXAM5MY64TiNrOzga8BV7j7W6n0htdMjuJeknp6BfBqsv84cEkS/zzgEsbeXZlMrVwnmNkZxIsb/CSV1sn2bsUG4NMWOx84mPxB2sn2lvZT39w+6pvVN7/vuNU3t5X65na0t3doRal2b8AniedCl4F9wONJ+inAI6lylwOvEX8rcXsqfSXxh8U24LtAb0ZxLwCeAF4HNgHzk/S1wH2pciuIv6kI6uo/CWwh/lD+d2AgL3EDv5XE9kLyeGM3tDdwLVABnk9tZ3WivRtdr8TTma5I9vuS9tuWtOfKVN3bk3pbgY9n0b4TiHtT8u+01r4bxrtmchL3PwAvJ/E9BZyRqvtnyfuwDbghT3Enz78EfKWuXqfb+0HilTsrxJ/fNwK3ALck+QbcnbyuLaRWje1ke2ub0Husvll9c7viVt88+XGrb84w7uT5l1Df3HSz5KAiIiIiIiIiuTDdpv6KiIiIiIhIzmmgKiIiIiIiIrmigaqIiIiIiIjkigaqIiIiIiIikisaqIqIiIiIiEiuaKAqIiIiIiIiuaKBqoiIiIiIiOSKBqoiIiIiIiKSK/8Pymjmb64hBsAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy.polynomial.chebyshev import Chebyshev\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a = 125\n",
    "n = 2 ** 7\n",
    "A = 1\n",
    "domain = [-A,A]\n",
    "\n",
    "sigmoid_a = lambda x: torch.sigmoid(torch.tensor(x*a)) - 0.5\n",
    "p_sigmoid = Chebyshev.interpolate(sigmoid_a,deg=n,domain=domain)\n",
    "\n",
    "tanh_a = lambda x: torch.tanh(torch.tensor(x*a))\n",
    "p_tanh = Chebyshev.interpolate(tanh_a, deg=n, domain=domain)\n",
    "\n",
    "x = np.linspace(*domain,100)\n",
    "y1 = sigmoid_a(x)\n",
    "pred1 = p_sigmoid(x)\n",
    "\n",
    "y2 = tanh_a(x)\n",
    "pred2 = p_tanh(x)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(16,4))\n",
    "\n",
    "# plot the function\n",
    "ax1.plot(x,y1, 'g', label=\"Sigmoid\")\n",
    "ax1.plot(x,pred1,\"b-\", label=f\"Polynomial approximation\")\n",
    "ax1.legend()\n",
    "\n",
    "# plot the function\n",
    "ax2.plot(x,y2, 'g', label=\"Tanh\")\n",
    "ax2.plot(x,pred2,\"b-\", label=f\"Polynomial approximation\")\n",
    "ax2.legend()\n",
    "\n",
    "# show the plot\n",
    "fig.suptitle(f\"Tchebytchev polynomials with expansion a={a} and degree n={n}\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danywin/.local/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/home/danywin/.local/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of sigmoid : 0.17564503848552704\n",
      "Loss of tanh : 1.7522064447402954\n",
      "Mean derivative of sigmoid : 24.735008239746094\n",
      "Mean derivative of tanh : 56.3404426574707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danywin/.local/lib/python3.6/site-packages/numpy/polynomial/chebyshev.py:1156: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return c0 + c1*x\n",
      "/home/danywin/.local/lib/python3.6/site-packages/numpy/polynomial/chebyshev.py:1155: RuntimeWarning: overflow encountered in double_scalars\n",
      "  c1 = tmp + c1*x2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saturation point of 0.9 for sigmoid : 157107 * 0.001\n",
      "Saturation point of 0.9 for tanh : 20 * 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danywin/.local/lib/python3.6/site-packages/numpy/polynomial/chebyshev.py:1156: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return c0 + c1*x\n"
     ]
    }
   ],
   "source": [
    "eps = 0.005\n",
    "\n",
    "x = torch.linspace(-eps,eps,)\n",
    "delta_x = x[1] - x[0]\n",
    "\n",
    "l_sigmoid = torch.norm(p_sigmoid(x) - sigmoid_a(x))\n",
    "l_tanh = torch.norm(p_tanh(x) - tanh_a(x))\n",
    "\n",
    "print(f\"Loss of sigmoid : {l_sigmoid}\")\n",
    "print(f\"Loss of tanh : {l_tanh}\")\n",
    "\n",
    "a,b = len(x) // 2 - len(x) // 4, len(x) // 2 + len(x) // 4\n",
    "\n",
    "def derivative(f,x,i,delta_x):\n",
    "    output = (f(x[i+1]) - f(x[i])) / delta_x\n",
    "    return output\n",
    "\n",
    "derivatives_tanh = []\n",
    "derivatives_sigmoid = []\n",
    "\n",
    "for i in range(a,b):\n",
    "    derivatives_sigmoid.append(derivative(p_sigmoid,x,i,delta_x))\n",
    "    derivatives_tanh.append(derivative(p_tanh,x,i,delta_x))\n",
    "    \n",
    "print(f\"Mean derivative of sigmoid : {torch.tensor(derivatives_sigmoid).mean()}\")\n",
    "print(f\"Mean derivative of tanh : {torch.tensor(derivatives_tanh).mean()}\")\n",
    "\n",
    "saturation = 0.9\n",
    "precision = 1e-3\n",
    "\n",
    "i = 0\n",
    "while p_sigmoid(i * precision) <= saturation:\n",
    "    i += 1\n",
    "print(f\"Saturation point of {saturation} for sigmoid : {i} * {precision}\")\n",
    "\n",
    "i = 0\n",
    "while p_tanh(i * precision) <= saturation:\n",
    "    i += 1\n",
    "print(f\"Saturation point of {saturation} for tanh : {i} * {precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The binary tree structure has 13 nodes and has the following tree structure:\n",
      "node=0 test node: go to node 1 if X[:, 3] <= 0.2916666641831398 else to node 2.\n",
      "\tnode=1 leaf node.\n",
      "\tnode=2 test node: go to node 3 if X[:, 2] <= 0.6637930870056152 else to node 8.\n",
      "\t\tnode=3 test node: go to node 4 if X[:, 3] <= 0.6458333432674408 else to node 5.\n",
      "\t\t\tnode=4 leaf node.\n",
      "\t\t\tnode=5 test node: go to node 6 if X[:, 1] <= 0.4583333283662796 else to node 7.\n",
      "\t\t\t\tnode=6 leaf node.\n",
      "\t\t\t\tnode=7 leaf node.\n",
      "\t\tnode=8 test node: go to node 9 if X[:, 3] <= 0.6875 else to node 12.\n",
      "\t\t\tnode=9 test node: go to node 10 if X[:, 3] <= 0.6458333432674408 else to node 11.\n",
      "\t\t\t\tnode=10 leaf node.\n",
      "\t\t\t\tnode=11 leaf node.\n",
      "\t\t\tnode=12 leaf node.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "estimator = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "estimator.fit(X_train, y_train)\n",
    "\n",
    "n_nodes = estimator.tree_.node_count\n",
    "children_left = estimator.tree_.children_left\n",
    "children_right = estimator.tree_.children_right\n",
    "feature = estimator.tree_.feature\n",
    "threshold = estimator.tree_.threshold\n",
    "\n",
    "# The tree structure can be traversed to compute various properties such\n",
    "# as the depth of each node and whether or not it is a leaf.\n",
    "node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "stack = [(0, -1)]  # seed is the root node id and its parent depth\n",
    "while len(stack) > 0:\n",
    "    node_id, parent_depth = stack.pop()\n",
    "    node_depth[node_id] = parent_depth + 1\n",
    "\n",
    "    # If we have a test node\n",
    "    if (children_left[node_id] != children_right[node_id]):\n",
    "        stack.append((children_left[node_id], parent_depth + 1))\n",
    "        stack.append((children_right[node_id], parent_depth + 1))\n",
    "    else:\n",
    "        is_leaves[node_id] = True\n",
    "        \n",
    "print(\"The binary tree structure has %s nodes and has \"\n",
    "      \"the following tree structure:\"\n",
    "      % n_nodes)\n",
    "for i in range(n_nodes):\n",
    "    if is_leaves[i]:\n",
    "        print(\"%snode=%s leaf node.\" % (node_depth[i] * \"\\t\", i))\n",
    "    else:\n",
    "        print(\"%snode=%s test node: go to node %s if X[:, %s] <= %s else to \"\n",
    "              \"node %s.\"\n",
    "              % (node_depth[i] * \"\\t\",\n",
    "                 i,\n",
    "                 children_left[i],\n",
    "                 feature[i],\n",
    "                 threshold[i],\n",
    "                 children_right[i],\n",
    "                 ))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def compute_leaves(n_nodes, children_left, children_right):\n",
    "    # The tree structure can be traversed to compute various properties such\n",
    "    # as the depth of each node and whether or not it is a leaf.\n",
    "    node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "\n",
    "    is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "    stack = [(0, -1)]  # seed is the root node id and its parent depth\n",
    "    while len(stack) > 0:\n",
    "        node_id, parent_depth = stack.pop()\n",
    "        node_depth[node_id] = parent_depth + 1\n",
    "\n",
    "        # If we have a test node\n",
    "        if (children_left[node_id] != children_right[node_id]):\n",
    "            stack.append((children_left[node_id], parent_depth + 1))\n",
    "            stack.append((children_right[node_id], parent_depth + 1))\n",
    "        else:\n",
    "            is_leaves[node_id] = True\n",
    "\n",
    "    return node_depth, is_leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_linear_node_comparator(tree: BaseDecisionTree) -> nn.Linear:\n",
    "    \n",
    "    n_nodes = tree.tree_.node_count\n",
    "    children_left = tree.tree_.children_left\n",
    "    children_right = tree.tree_.children_right\n",
    "    \n",
    "    feature = tree.tree_.feature\n",
    "    threshold = tree.tree_.threshold\n",
    "    \n",
    "    d = tree.n_features_\n",
    "\n",
    "    node_depth, is_leaves = compute_leaves(n_nodes, children_left, children_right)\n",
    "    internal_nodes = [i for i,isLeaf in enumerate(is_leaves)if not isLeaf]\n",
    "\n",
    "    W = []\n",
    "    B = []\n",
    "\n",
    "    for node in internal_nodes:\n",
    "        w = np.zeros(d)\n",
    "        w[feature[node]] = 1\n",
    "\n",
    "        b = - threshold[node]\n",
    "        W.append(w)\n",
    "        B.append(b)\n",
    "\n",
    "    W = np.stack(W)\n",
    "    B = np.stack(B)\n",
    "\n",
    "    linear = nn.Linear(W.shape[1],W.shape[0])\n",
    "    linear.weight.data = torch.tensor(W).float()\n",
    "    linear.bias.data = torch.tensor(B).float()\n",
    "\n",
    "    return linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=4, out_features=6, bias=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_linear_node_comparator(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[0., 0., 0., 1.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 0., 1.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1.],\n",
       "         [0., 0., 0., 1.]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.2917, -0.6638, -0.6458, -0.4583, -0.6875, -0.6458],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = X.shape[1]\n",
    "\n",
    "linear = create_linear_node_comparator(estimator)\n",
    "\n",
    "linear.weight, linear.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_parent_of(n_nodes, is_leaves, children_left, children_right,left_value=0,right_value=1):\n",
    "    parentOf = {}\n",
    "\n",
    "    for i in range(n_nodes):\n",
    "        if not is_leaves[i]:\n",
    "            parentOf[children_left[i]] = (i,left_value)\n",
    "            parentOf[children_right[i]] = (i,right_value)\n",
    "    return parentOf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: (0, 0),\n",
       " 2: (0, 1),\n",
       " 3: (2, 0),\n",
       " 8: (2, 1),\n",
       " 4: (3, 0),\n",
       " 5: (3, 1),\n",
       " 6: (5, 0),\n",
       " 7: (5, 1),\n",
       " 9: (8, 0),\n",
       " 12: (8, 1),\n",
       " 10: (9, 0),\n",
       " 11: (9, 1)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2nodes = [i for i,isLeaf in enumerate(is_leaves) if not isLeaf]\n",
    "nodes2idx = {node : i for i, node in enumerate(idx2nodes)}\n",
    "\n",
    "idx2leaves = [i for i,isLeaf in enumerate(is_leaves) if isLeaf]\n",
    "leaves2idx = { leaf : i for i,leaf in enumerate(idx2leaves)}\n",
    "\n",
    "parentOf = create_parent_of(n_nodes,is_leaves,children_left,children_right)\n",
    "parentOf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_leaf_to_path(n_nodes, is_leaves, children_left, children_right,left_value=0,right_value=1):\n",
    "    parentOf = create_parent_of(n_nodes, is_leaves, children_left, children_right,left_value,right_value)\n",
    "    leafToPath = []\n",
    "\n",
    "    for i,isLeaf in enumerate(is_leaves):\n",
    "        if isLeaf:\n",
    "            node = i\n",
    "            path = []\n",
    "\n",
    "            parent = parentOf[node]\n",
    "\n",
    "            while parent[0] != 0:\n",
    "                path.append(parent)\n",
    "                parent = parentOf[parent[0]]\n",
    "\n",
    "            path.append(parent)\n",
    "            leafToPath.append(path[::-1])\n",
    "            \n",
    "    return leafToPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0)],\n",
       " [(0, 1), (2, 0), (3, 0)],\n",
       " [(0, 1), (2, 0), (3, 1), (5, 0)],\n",
       " [(0, 1), (2, 0), (3, 1), (5, 1)],\n",
       " [(0, 1), (2, 1), (8, 0), (9, 0)],\n",
       " [(0, 1), (2, 1), (8, 0), (9, 1)],\n",
       " [(0, 1), (2, 1), (8, 1)]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leafToPath = create_leaf_to_path(n_nodes,is_leaves,children_left,children_right,left_value=0)\n",
    "leafToPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (2, 0), (3, 0)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = leafToPath[1]\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (2, 0), (3, 0)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (2, 0), (3, 0)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leafToPath = create_leaf_to_path(n_nodes,is_leaves,children_left,children_right)\n",
    "path = leafToPath[1]\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bits = [v for k,v in path]\n",
    "bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0, 4: 1, 6: 2, 7: 3, 10: 4, 11: 5, 12: 6}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaves2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_depth[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0, 4: 1, 6: 2, 7: 3, 10: 4, 11: 5, 12: 6}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaves2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Bits outside of -1 and 1 : [1, 0, 0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-bc3fbb1a3e6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mleaf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbits\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Bits outside of -1 and 1 : {bits}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnodes2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Bits outside of -1 and 1 : [1, 0, 0]"
     ]
    }
   ],
   "source": [
    "eps = 0.5\n",
    "leaf = 4\n",
    "bits = [v for k,v in path]\n",
    "assert set(bits) == set([-1,1]), f\"Bits outside of -1 and 1 : {bits}\"\n",
    "\n",
    "idx = [nodes2idx[k] for k,v in path]\n",
    "\n",
    "K = len(nodes2idx)\n",
    "w = np.zeros(K)\n",
    "\n",
    "w[idx] = bits\n",
    "b = -node_depth[leaf] + eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def tanh_path_to_weight(path, nodes2idx, node_depth, leaf, eps=0.5):\n",
    "    bits = [v for k,v in path]\n",
    "    assert (set(bits) == set([-1,1])) or (set(bits) == set([-1])) or (set(bits) == set([1])), f\"Bits outside of -1 and 1 : {bits}\"\n",
    "    \n",
    "    idx = [nodes2idx[k] for k,v in path]\n",
    "    \n",
    "    K = len(nodes2idx)\n",
    "    w = np.zeros(K)\n",
    "    \n",
    "    w[idx] = bits\n",
    "    b = -node_depth[leaf] + eps\n",
    "    \n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def tanh_path_to_linear(leafToPath, nodes2idx, idx2leaves, node_depth, eps=0.5):\n",
    "    \n",
    "    # For each leaf, we compute the linear layer to match it\n",
    "    W = []\n",
    "    B = []\n",
    "    for leaf_id, path in enumerate(leafToPath):\n",
    "        leaf = idx2leaves[leaf_id]\n",
    "        w,b = tanh_path_to_weight(path, nodes2idx, node_depth, leaf, eps)\n",
    "        W.append(w)\n",
    "        B.append(b)\n",
    "\n",
    "    W = np.stack(W)\n",
    "    B = np.stack(B)\n",
    "    \n",
    "    # We divide the weights \n",
    "    K = len(nodes2idx)\n",
    "    \n",
    "    linear = nn.Linear(W.shape[1],W.shape[0])\n",
    "    linear.weight.data = torch.tensor(W).float() / (2 * K)\n",
    "    linear.bias.data = torch.tensor(B).view(-1).float() / (2 * K)\n",
    "    \n",
    "    return linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def tanh_linear_leaf_matcher(tree: BaseDecisionTree, eps=0.5) -> nn.Linear:\n",
    "    \n",
    "    n_nodes = tree.tree_.node_count\n",
    "    children_left = tree.tree_.children_left\n",
    "    children_right = tree.tree_.children_right\n",
    "    node_depth, is_leaves = compute_leaves(n_nodes, children_left, children_right)\n",
    "    \n",
    "    leafToPath = create_leaf_to_path(n_nodes,is_leaves,children_left,children_right,left_value=-1)\n",
    "    \n",
    "    internal_nodes = [i for i,isLeaf in enumerate(is_leaves) if not isLeaf]\n",
    "    leaves = [i for i,isLeaf in enumerate(is_leaves) if isLeaf]\n",
    "    \n",
    "    nodes2idx = {node : i for i, node in enumerate(internal_nodes)}\n",
    "    leaves2idx = { leaf : i for i,leaf in enumerate(leaves)}\n",
    "    \n",
    "    matcher = tanh_path_to_linear(leafToPath, nodes2idx, idx2leaves, node_depth, eps)\n",
    "    \n",
    "    return matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 1., -1., -1.,  0.,  0.,  0.],\n",
       "         [ 1., -1.,  1., -1.,  0.,  0.],\n",
       "         [ 1., -1.,  1.,  1.,  0.,  0.],\n",
       "         [ 1.,  1.,  0.,  0., -1., -1.],\n",
       "         [ 1.,  1.,  0.,  0., -1.,  1.],\n",
       "         [ 1.,  1.,  0.,  0.,  1.,  0.]], grad_fn=<MulBackward0>),\n",
       " tensor([-0.5000, -2.5000, -3.5000, -3.5000, -3.5000, -3.5000, -2.5000],\n",
       "        grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matcher = tanh_linear_leaf_matcher(estimator)\n",
    "matcher.weight * 12, matcher.bias * 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def sigmoid_path_to_weight(path, nodes2idx, eps=0.5):\n",
    "    # This is the target of the Bitcomparison\n",
    "    bits = [v for k,v in path]\n",
    "    bit_comparison = BitComparison(bits, eps=eps)\n",
    "    \n",
    "    # Those are the indexes to be replaced by the corresponding weights\n",
    "    idx = [nodes2idx[k] for k,v in path]\n",
    "    \n",
    "    K = len(nodes2idx)\n",
    "    w = np.zeros(K)\n",
    "    \n",
    "    w[idx] = bit_comparison.linear.weight.data.numpy().reshape(-1)\n",
    "    b = bit_comparison.linear.bias.data.numpy()\n",
    "    \n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (2, 0), (3, 0)]\n",
      "[ 1. -1. -1.  0.  0.  0.] [-0.5]\n"
     ]
    }
   ],
   "source": [
    "print(path)\n",
    "w,b = sigmoid_path_to_weight(path,nodes2idx)\n",
    "print(w,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0)],\n",
       " [(0, 1), (2, 0), (3, 0)],\n",
       " [(0, 1), (2, 0), (3, 1), (5, 0)],\n",
       " [(0, 1), (2, 0), (3, 1), (5, 1)],\n",
       " [(0, 1), (2, 1), (8, 0), (9, 0)],\n",
       " [(0, 1), (2, 1), (8, 0), (9, 1)],\n",
       " [(0, 1), (2, 1), (8, 1)]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leafToPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def sigmoid_path_to_linear(leafToPath, nodes2idx, eps=0.5):\n",
    "    \n",
    "    # For each leaf, we compute the linear layer to match it\n",
    "    W = []\n",
    "    B = []\n",
    "    for path in leafToPath:\n",
    "        w,b = sigmoid_path_to_weight(path,nodes2idx, eps=eps)\n",
    "        W.append(w)\n",
    "        B.append(b)\n",
    "\n",
    "    W = np.stack(W)\n",
    "    B = np.stack(B)\n",
    "    \n",
    "    # We divide the weights \n",
    "    K = len(nodes2idx)\n",
    "    \n",
    "    linear = nn.Linear(W.shape[1],W.shape[0])\n",
    "    linear.weight.data = torch.tensor(W).float() / K\n",
    "    linear.bias.data = torch.tensor(B).view(-1).float() / K\n",
    "    \n",
    "    return linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def sigmoid_linear_leaf_matcher(tree: BaseDecisionTree, eps=0.5) -> nn.Linear:\n",
    "    \n",
    "    n_nodes = tree.tree_.node_count\n",
    "    children_left = tree.tree_.children_left\n",
    "    children_right = tree.tree_.children_right\n",
    "    node_depth, is_leaves = compute_leaves(n_nodes, children_left, children_right)\n",
    "    \n",
    "    leafToPath = create_leaf_to_path(n_nodes,is_leaves,children_left,children_right)\n",
    "    \n",
    "    internal_nodes = [i for i,isLeaf in enumerate(is_leaves) if not isLeaf]\n",
    "    nodes2idx = {node : i for i, node in enumerate(internal_nodes)}\n",
    "    \n",
    "    matcher = sigmoid_path_to_linear(leafToPath,nodes2idx, eps=0.5)\n",
    "    \n",
    "    return matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.1667,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.1667, -0.1667, -0.1667,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.1667, -0.1667,  0.1667, -0.1667,  0.0000,  0.0000],\n",
       "         [ 0.1667, -0.1667,  0.1667,  0.1667,  0.0000,  0.0000],\n",
       "         [ 0.1667,  0.1667,  0.0000,  0.0000, -0.1667, -0.1667],\n",
       "         [ 0.1667,  0.1667,  0.0000,  0.0000, -0.1667,  0.1667],\n",
       "         [ 0.1667,  0.1667,  0.0000,  0.0000,  0.1667,  0.0000]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0833, -0.0833, -0.2500, -0.4167, -0.2500, -0.4167, -0.4167],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matcher = sigmoid_linear_leaf_matcher(estimator)\n",
    "matcher.weight, matcher.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4512, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.3902, 0.0000, 0.0122, 0.0000, 0.0122, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0366, 0.0000, 0.0366, 0.0000, 0.4268]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.head.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def sigmoid_classification_head(tree: BaseDecisionTree) -> nn.Linear:\n",
    "    n_nodes = tree.tree_.node_count\n",
    "    children_left = tree.tree_.children_left\n",
    "    children_right = tree.tree_.children_right\n",
    "    node_depth, is_leaves = compute_leaves(n_nodes, children_left, children_right)\n",
    "    \n",
    "    leaves = [i for i,isLeaf in enumerate(is_leaves) if isLeaf]\n",
    "    \n",
    "    values = tree.tree_.value[[0] + idx2leaves]\n",
    "    values = torch.tensor(values).float()\n",
    "    values = values.squeeze(1)\n",
    "\n",
    "    root_values = values[0]\n",
    "    leaf_values = values[1:]\n",
    "\n",
    "    leaf_values = (leaf_values - root_values.unsqueeze(0)) / root_values.max()\n",
    "    root_values = root_values / root_values.max()\n",
    "\n",
    "    head = nn.Linear(*leaf_values.shape)\n",
    "    head.weight.data = leaf_values.T\n",
    "    head.bias.data = root_values\n",
    "    \n",
    "    return head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[ 0.0000, -0.9024, -0.9024, -0.9024, -0.9024, -0.9024, -0.9024],\n",
       "         [-0.8293, -0.0488, -0.8293, -0.8049, -0.8293, -0.8049, -0.8293],\n",
       "         [-1.0000, -1.0000, -0.9268, -1.0000, -0.9268, -1.0000, -0.1463]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.9024, 0.8293, 1.0000], requires_grad=True))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head = sigmoid_classification_head(estimator)\n",
    "head.weight, head.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from sklearn.tree import BaseDecisionTree\n",
    "from sklearn.base import is_classifier\n",
    "\n",
    "from typing import Callable\n",
    "from numpy.polynomial.chebyshev import Chebyshev\n",
    "\n",
    "DEFAULT_POLYNOMIAL_DEGREE = 25\n",
    "DEFAULT_DILATATION_FACTOR = 100.0\n",
    "DEFAULT_BOUND = 1.0\n",
    "\n",
    "class DecisionTree(nn.Module):\n",
    "    def __init__(self, tree: BaseDecisionTree, \n",
    "                 activation: Callable, \n",
    "                 create_linear_leaf_matcher: Callable,\n",
    "                 create_regression_head: Callable,\n",
    "                 create_classifier_head: Callable,\n",
    "                 dilatation_factor : float = DEFAULT_DILATATION_FACTOR,\n",
    "                 use_polynomial : bool = False, \n",
    "                 polynomial_degree : int = DEFAULT_POLYNOMIAL_DEGREE, bound: float = DEFAULT_BOUND,\n",
    "                 *args,**kwargs):\n",
    "        super(DecisionTree, self).__init__()\n",
    "        \n",
    "        activation_fn = lambda x: activation(x * dilatation_factor)\n",
    "        if use_polynomial:\n",
    "            domain = [-bound, bound]\n",
    "            activation_fn_numpy = lambda x: activation_fn(torch.tensor(x))\n",
    "            self.activation = Chebyshev.interpolate(activation_fn_numpy,deg=polynomial_degree,domain=domain)\n",
    "        else:\n",
    "            self.activation = activation_fn\n",
    "        \n",
    "        self.comparator = create_linear_node_comparator(tree)\n",
    "        self.matcher = create_linear_leaf_matcher(tree)\n",
    "        \n",
    "        if is_classifier(tree):\n",
    "            self.head = create_classifier_head(tree)\n",
    "        else:\n",
    "            self.head = create_regression_head(tree)\n",
    "            \n",
    "    def forward(self,x):\n",
    "        comparisons = self.comparator(x)\n",
    "        comparisons = self.activation(comparisons)\n",
    "        \n",
    "        matches = self.matcher(comparisons)\n",
    "        matches = self.activation(matches)\n",
    "        \n",
    "        output = self.head(matches)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def raise_error_wrong_tree(*args,**kwargs):\n",
    "    raise Exception(\"Wrong supervised tree used\")\n",
    "\n",
    "class SigmoidDecisionTree(DecisionTree):\n",
    "    def __init__(self, tree: BaseDecisionTree,\n",
    "                 create_regression_head: Callable,\n",
    "                 create_classifier_head: Callable,\n",
    "                 dilatation_factor : float = DEFAULT_DILATATION_FACTOR,\n",
    "                 use_polynomial : bool = False, \n",
    "                 polynomial_degree : int = DEFAULT_POLYNOMIAL_DEGREE, bound: float = DEFAULT_BOUND,eps=0.5):\n",
    "        \n",
    "        activation = torch.sigmoid\n",
    "        create_linear_leaf_matcher = partial(sigmoid_linear_leaf_matcher,eps=eps)\n",
    "        \n",
    "        super().__init__(tree, \n",
    "                 activation=activation, \n",
    "                 create_linear_leaf_matcher=create_linear_leaf_matcher,\n",
    "                 create_regression_head=create_regression_head,\n",
    "                 create_classifier_head=create_classifier_head,\n",
    "                 dilatation_factor=dilatation_factor,\n",
    "                 use_polynomial=use_polynomial, polynomial_degree=polynomial_degree, bound=bound)\n",
    "        \n",
    "class SigmoidClassificationTree(SigmoidDecisionTree):\n",
    "    def __init__(self, tree: BaseDecisionTree,\n",
    "                 dilatation_factor : float = DEFAULT_DILATATION_FACTOR,\n",
    "                 use_polynomial : bool = False, \n",
    "                 polynomial_degree : int = DEFAULT_POLYNOMIAL_DEGREE, bound: float = DEFAULT_BOUND,eps=0.5):\n",
    "        create_classifier_head = sigmoid_classification_head\n",
    "        create_regression_head = raise_error_wrong_tree\n",
    "        \n",
    "        super().__init__(tree,\n",
    "                         create_classifier_head=create_classifier_head,\n",
    "                         create_regression_head=create_regression_head,\n",
    "                         dilatation_factor=dilatation_factor,\n",
    "                         use_polynomial=use_polynomial, polynomial_degree=polynomial_degree, bound=bound,eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def tanh_classification_head(tree: BaseDecisionTree) -> nn.Linear:\n",
    "    n_nodes = tree.tree_.node_count\n",
    "    children_left = tree.tree_.children_left\n",
    "    children_right = tree.tree_.children_right\n",
    "    node_depth, is_leaves = compute_leaves(n_nodes, children_left, children_right)\n",
    "    \n",
    "    leaves = [i for i,isLeaf in enumerate(is_leaves) if isLeaf]\n",
    "    \n",
    "    leaf_values = tree.tree_.value[leaves]\n",
    "    leaf_values = torch.tensor(leaf_values).float()\n",
    "    \n",
    "    leaf_values = leaf_values.squeeze(1) / tree.tree_.value[0].max()\n",
    "    \n",
    "    # We divide by 2 because we have -1 and 1 bits\n",
    "    bias = leaf_values.sum(dim=0) / 2\n",
    "    leaf_values = leaf_values / 2\n",
    "\n",
    "    head = nn.Linear(*leaf_values.shape)\n",
    "    head.weight.data = leaf_values.T\n",
    "    head.bias.data = bias\n",
    "    \n",
    "    return head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TanhDecisionTree(DecisionTree):\n",
    "    def __init__(self, tree: BaseDecisionTree,\n",
    "                 create_regression_head: Callable,\n",
    "                 create_classifier_head: Callable,\n",
    "                 dilatation_factor : float = DEFAULT_DILATATION_FACTOR,\n",
    "                 use_polynomial : bool = False, \n",
    "                 polynomial_degree : int = DEFAULT_POLYNOMIAL_DEGREE, bound: float = DEFAULT_BOUND,eps=0.5):\n",
    "        activation = torch.tanh\n",
    "        create_linear_leaf_matcher = partial(tanh_linear_leaf_matcher,eps=eps)\n",
    "        \n",
    "        super().__init__(tree, \n",
    "                 activation=activation, \n",
    "                 create_linear_leaf_matcher=create_linear_leaf_matcher,\n",
    "                 create_regression_head=create_regression_head,\n",
    "                 create_classifier_head=create_classifier_head,\n",
    "                 dilatation_factor=dilatation_factor,\n",
    "                 use_polynomial=use_polynomial, polynomial_degree=polynomial_degree, bound=bound)\n",
    "        \n",
    "class TanhClassificationTree(TanhDecisionTree):\n",
    "    def __init__(self, tree: BaseDecisionTree,\n",
    "                 dilatation_factor : float = DEFAULT_DILATATION_FACTOR,\n",
    "                 use_polynomial : bool = False, \n",
    "                 polynomial_degree : int = DEFAULT_POLYNOMIAL_DEGREE, bound: float = DEFAULT_BOUND,eps=0.5):\n",
    "        create_classifier_head = tanh_classification_head\n",
    "        create_regression_head = raise_error_wrong_tree\n",
    "        \n",
    "        super().__init__(tree,\n",
    "                         create_classifier_head=create_classifier_head,\n",
    "                         create_regression_head=create_regression_head,\n",
    "                         dilatation_factor=dilatation_factor,\n",
    "                         use_polynomial=use_polynomial, polynomial_degree=polynomial_degree, bound=bound,eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def check_output_range(m, i, o, threshold=1):\n",
    "    rows_outside_range = ((torch.abs(o) > threshold).float().sum(dim=1) > 0).numpy()\n",
    "    idx_outside_range = np.arange(len(rows_outside_range))[rows_outside_range]\n",
    "    \n",
    "    assert len(idx_outside_range) == 0, f\"\"\"Out of range outputs for module {m}: \\n \n",
    "    {idx_outside_range} \\n\n",
    "    Rows with outside range : \\n\n",
    "    {o.numpy()[idx_outside_range]}\"\"\"\n",
    "\n",
    "def register_output_check(model, threshold=1):\n",
    "    for c in model.children():\n",
    "        if isinstance(c,nn.Linear):\n",
    "            hook = partial(check_output_range, threshold=threshold)\n",
    "            c.register_forward_hook(hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 432x288 with 1 Axes>,\n",
       " <matplotlib.axes._subplots.AxesSubplot at 0x7f9add066c50>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dilatation_factor = 16\n",
    "polynomial_degree = 2 ** 4\n",
    "\n",
    "plot_graph_function_approximation(torch.sigmoid,dilatation_factor=dilatation_factor,polynomial_degree=polynomial_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9464)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(X_train).float()\n",
    "tree = estimator\n",
    "model = SigmoidClassificationTree(tree,use_polynomial=True,\n",
    "                                  dilatation_factor=dilatation_factor, polynomial_degree=polynomial_degree)\n",
    "register_output_check(model, threshold=1)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(x)\n",
    "pred = output.argmax(dim=1)\n",
    "y = estimator.predict(X_train)\n",
    "(pred == torch.tensor(y)).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9464)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(X_train).float()\n",
    "tree = estimator\n",
    "model = TanhClassificationTree(tree,use_polynomial=True,\n",
    "                                  dilatation_factor=dilatation_factor, polynomial_degree=polynomial_degree)\n",
    "register_output_check(model, threshold=1)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(x)\n",
    "pred = output.argmax(dim=1)\n",
    "y = estimator.predict(X_train)\n",
    "(pred == torch.tensor(y)).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(x)\n",
    "label = torch.tensor(y_train).long()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(pred,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.5226e-02,  7.3443e-03, -4.5732e-02, -3.7871e-02],\n",
       "         [-4.9783e-02, -2.7853e-02, -7.8843e-02, -1.0089e-01],\n",
       "         [ 5.1247e-02,  3.9488e-02,  5.1160e-02,  4.8214e-02],\n",
       "         [ 6.1523e-03,  3.6545e-03,  7.2192e-03,  8.1534e-03],\n",
       "         [-1.1175e-01, -6.4472e-02, -1.3726e-01, -1.3613e-01],\n",
       "         [ 7.8507e-04, -9.9554e-05,  1.2871e-03,  9.3524e-04]]),\n",
       " Parameter containing:\n",
       " tensor([[0., 0., 0., 1.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 0., 1.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1.],\n",
       "         [0., 0., 0., 1.]], requires_grad=True),\n",
       " tensor([-0.0609, -0.0748,  0.0969,  0.0088, -0.1795,  0.0004]),\n",
       " Parameter containing:\n",
       " tensor([-0.2917, -0.6638, -0.6458, -0.4583, -0.6875, -0.6458],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.comparator.weight.grad, model.comparator.weight, model.comparator.bias.grad, model.comparator.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5.6297e-01,  2.7994e-01,  3.0129e-01, -1.7548e-01,  2.6102e-01,\n",
       "           3.0129e-01],\n",
       "         [-3.5946e-01, -2.2524e-02, -4.6209e-03,  8.0025e-02,  1.5869e-02,\n",
       "          -4.6209e-03],\n",
       "         [-1.9923e-02, -2.0904e-02, -2.5816e-02, -6.4199e-03, -2.3795e-02,\n",
       "          -2.5816e-02],\n",
       "         [ 5.9223e-04,  1.7812e-03,  2.1452e-03,  2.4816e-04,  2.3098e-03,\n",
       "           2.1452e-03],\n",
       "         [ 6.8858e-03, -4.0357e-03, -2.5161e-03,  1.8481e-03, -2.2850e-03,\n",
       "          -2.5161e-03],\n",
       "         [ 3.1441e-03,  3.9137e-03,  4.2875e-03,  1.1285e-03,  4.1490e-03,\n",
       "           4.2875e-03],\n",
       "         [-5.3463e-01, -4.3756e-01, -4.9078e-01, -2.0055e-01, -4.5164e-01,\n",
       "          -4.9078e-01]]), Parameter containing:\n",
       " tensor([[-0.1667,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.1667, -0.1667, -0.1667,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.1667, -0.1667,  0.1667, -0.1667,  0.0000,  0.0000],\n",
       "         [ 0.1667, -0.1667,  0.1667,  0.1667,  0.0000,  0.0000],\n",
       "         [ 0.1667,  0.1667,  0.0000,  0.0000, -0.1667, -0.1667],\n",
       "         [ 0.1667,  0.1667,  0.0000,  0.0000, -0.1667,  0.1667],\n",
       "         [ 0.1667,  0.1667,  0.0000,  0.0000,  0.1667,  0.0000]],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.matcher.weight.grad, model.matcher.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0870,  0.0247,  0.0258,  0.0106,  0.0241,  0.0157,  0.0606],\n",
       "         [ 0.0524, -0.0823, -0.0070,  0.0026, -0.0340,  0.0166,  0.0509],\n",
       "         [ 0.0346,  0.0576, -0.0188, -0.0132,  0.0099, -0.0323, -0.1116]]),\n",
       " Parameter containing:\n",
       " tensor([[0.9024, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.7805, 0.0000, 0.0244, 0.0000, 0.0244, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0732, 0.0000, 0.0732, 0.0000, 0.8537]],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.head.weight.grad, model.head.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9464)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(X_train).float()\n",
    "tree = estimator\n",
    "model = TanhClassificationTree(tree,use_polynomial=True,\n",
    "                                  dilatation_factor=dilatation_factor, polynomial_degree=polynomial_degree)\n",
    "register_output_check(model, threshold=1)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(x)\n",
    "    pred = output.argmax(dim=1)\n",
    "y = estimator.predict(X_train)\n",
    "(pred == torch.tensor(y)).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons = model.comparator(x)\n",
    "a_comparisons = model.activation(comparisons)\n",
    "\n",
    "matches = model.matcher(comparisons)\n",
    "a_matches = model.activation(matches)\n",
    "\n",
    "output = model.head(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (pred != torch.tensor(y)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 3, 5, 8, 9]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([112])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.29166666,  0.00862068, -0.06250006, -0.37499997, -0.10416669,\n",
       "        -0.06250006],\n",
       "       [ 0.29166666,  0.0258621 , -0.06250006, -0.12499997, -0.10416669,\n",
       "        -0.06250006],\n",
       "       [ 0.37500003, -0.07758617,  0.02083331, -0.24999999, -0.02083331,\n",
       "         0.02083331],\n",
       "       [ 0.41666666, -0.02586204,  0.06249994, -0.04166666,  0.02083331,\n",
       "         0.06249994],\n",
       "       [ 0.37500003,  0.00862068,  0.02083331, -0.04166666, -0.02083331,\n",
       "         0.02083331],\n",
       "       [ 0.41666666, -0.02586204,  0.06249994,  0.04166669,  0.02083331,\n",
       "         0.06249994]], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "comparisons.detach().numpy()[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0226065 ,  0.53126144,  0.28143188,  0.00404172,  0.15864669,\n",
       "         0.28143188],\n",
       "       [ 1.0226065 ,  0.59325624,  0.28143188,  0.10803522,  0.15864669,\n",
       "         0.28143188],\n",
       "       [ 0.99595827,  0.23401788,  0.5752907 , -0.02687919,  0.4247093 ,\n",
       "         0.5752907 ],\n",
       "       [ 0.988738  ,  0.40674394,  0.71856767,  0.35126743,  0.5752907 ,\n",
       "         0.71856767],\n",
       "       [ 0.99595827,  0.53126144,  0.5752907 ,  0.35126743,  0.4247093 ,\n",
       "         0.5752907 ],\n",
       "       [ 0.988738  ,  0.40674394,  0.71856767,  0.64873266,  0.5752907 ,\n",
       "         0.71856767]], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_comparisons.detach().numpy()[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[37.,  0.,  0.]],\n",
       "\n",
       "       [[ 0., 32.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  3.]],\n",
       "\n",
       "       [[ 0.,  1.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  3.]],\n",
       "\n",
       "       [[ 0.,  1.,  0.]],\n",
       "\n",
       "       [[ 0.,  0., 35.]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.tree_.value[idx2leaves]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03472222, -0.02574233, -0.15074235, -0.442409  , -0.1721743 ,\n",
       "        -0.35967433, -0.3839799 ],\n",
       "       [ 0.03472222, -0.0286159 , -0.19528258, -0.4036159 , -0.16930073,\n",
       "        -0.35680076, -0.38110632],\n",
       "       [ 0.02083333, -0.01137452, -0.12943009, -0.37943006, -0.20043102,\n",
       "        -0.36015323, -0.37056988],\n",
       "       [ 0.01388889, -0.01999521, -0.15888411, -0.33943966, -0.19875477,\n",
       "        -0.3445881 , -0.34806034],\n",
       "       [ 0.02083333, -0.02574233, -0.17852011, -0.35907567, -0.18606322,\n",
       "        -0.34578544, -0.3562021 ],\n",
       "       [ 0.01388889, -0.01999521, -0.172773  , -0.32555076, -0.19875477,\n",
       "        -0.3445881 , -0.34806034]], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches.detach().numpy()[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 6, 7, 10, 11, 12]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.2456876e-01,  4.0717018e-01,  5.6833252e-02,  1.1788622e-02,\n",
       "         2.4052277e-02, -3.6442280e-04,  6.2343478e-03],\n",
       "       [ 6.2456876e-01,  3.9696065e-01, -1.5120506e-03,  9.8398477e-03,\n",
       "         2.7931094e-02, -1.2688935e-03,  5.5673718e-03],\n",
       "       [ 5.7529074e-01,  4.5877376e-01,  9.8312348e-02,  5.1629841e-03,\n",
       "        -5.8923215e-03, -2.1582842e-04,  2.8478354e-03],\n",
       "       [ 5.5030900e-01,  4.2771468e-01,  4.3327749e-02, -7.0945472e-03,\n",
       "        -4.5168400e-03, -5.3164512e-03, -4.1372031e-03],\n",
       "       [ 5.7529074e-01,  4.0717015e-01,  1.6043767e-02, -5.5108964e-04,\n",
       "         7.5076222e-03, -4.9077272e-03, -1.4599264e-03],\n",
       "       [ 5.5030900e-01,  4.2771468e-01,  2.3264006e-02, -1.1965156e-02,\n",
       "        -4.5168400e-03, -5.3164512e-03, -4.1372031e-03]], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_matches.detach().numpy()[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(len(X_train))[(pred != torch.tensor(y)).numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nodes_to_linear' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-e9aecd6a8f5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcomparisons\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes_to_linear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx2nodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpaths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath_to_linear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleafToPath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnodes2idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nodes_to_linear' is not defined"
     ]
    }
   ],
   "source": [
    "comparisons = nodes_to_linear(idx2nodes,feature,threshold,d)\n",
    "paths = path_to_linear(leafToPath,nodes2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-e1098f7d6f75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomparisons\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'Tensor' object is not callable"
     ]
    }
   ],
   "source": [
    "z = comparisons(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-6f0cde8b139f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp_sigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "a = p_sigmoid(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = paths(a.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = p_sigmoid(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False, False, False, False, False],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [False, False, False, False,  True, False, False],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [False, False,  True, False, False, False, False],\n",
       "        [False, False, False, False,  True, False, False],\n",
       "        [False, False,  True, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [False,  True, False,  True, False, False, False],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [False,  True, False, False,  True, False, False],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [False, False, False, False,  True, False, False],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [False, False,  True, False, False, False, False],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [False,  True, False, False,  True, False, False],\n",
       "        [False, False, False, False, False, False, False],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [False, False, False,  True, False, False, False],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [ True, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [False,  True, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True],\n",
       "        [ True, False, False, False, False, False, False]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 0, 2, 0, 0, 1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2,\n",
       "       1, 0, 2, 1, 1, 1, 1, 2, 0, 0, 2, 1, 0, 0, 1, 0, 2, 1, 0, 1, 2, 1,\n",
       "       0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 1, 2,\n",
       "       2, 0, 0, 0, 1, 1, 0, 0, 1, 0, 2, 1, 2, 1, 0, 2, 0, 2, 0, 0, 2, 0,\n",
       "       2, 1, 1, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 1, 1, 1, 0, 0, 0, 2, 1,\n",
       "       2, 0])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.predict(X_train.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32mc:\\users\\daniel\\anaconda3\\envs\\emd\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m(1370)\u001b[0;36mlinear\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m   1368 \u001b[1;33m    \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   1369 \u001b[1;33m        \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m-> 1370 \u001b[1;33m        \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   1371 \u001b[1;33m    \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   1372 \u001b[1;33m        \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> bias\n",
      "Parameter containing:\n",
      "tensor([ 0.5000, -0.5000, -1.5000, -2.5000, -1.5000, -2.5000, -2.5000],\n",
      "       requires_grad=True)\n",
      "ipdb> input\n",
      "tensor([[ 0.9900, -0.1244, -0.0095,  0.1281, -0.1369, -0.0095],\n",
      "        [ 1.0365, -0.0444,  0.0179,  0.0580,  0.0757,  0.0179],\n",
      "        [ 1.0236,  1.1258,  0.9821,  0.1281,  1.0914,  0.9821],\n",
      "        [ 0.0696,  0.0122, -0.0125,  0.8719,  0.0243, -0.0125],\n",
      "        [ 0.9918,  0.7414,  0.9554,  0.5000,  0.9243,  0.9554],\n",
      "        [-0.0986, -0.0312,  0.0300,  1.0365,  0.0357,  0.0300],\n",
      "        [ 0.0696, -0.0208, -0.0125,  0.9304,  0.0243, -0.0125],\n",
      "        [ 1.0986,  0.0696,  0.0446,  0.0402, -0.0235,  0.0446],\n",
      "        [ 0.9920,  1.1258,  1.0095,  0.1281,  0.6964,  1.0095],\n",
      "        [ 1.0012,  1.1244,  1.0524,  1.0986,  1.0235,  1.0524],\n",
      "        [ 0.9900,  0.5825, -0.0095, -0.0418, -0.1369, -0.0095],\n",
      "        [ 0.9920,  1.0897,  1.0095,  0.0696,  0.6964,  1.0095],\n",
      "        [ 1.1303,  0.0020,  0.0757,  0.0696,  0.0446,  0.0757],\n",
      "        [ 0.9918,  0.9589,  0.9554,  0.1281,  0.9243,  0.9554],\n",
      "        [ 1.0462,  0.1172,  0.3036,  1.0986, -0.0095,  0.3036],\n",
      "        [ 1.1303,  0.0411,  0.0757,  0.0100,  0.0446,  0.0757],\n",
      "        [ 0.9920,  0.4175,  1.0095, -0.0365,  0.6964,  1.0095],\n",
      "        [ 0.9900,  0.7414, -0.0095, -0.1303, -0.1369, -0.0095],\n",
      "        [ 1.0418, -0.0792,  0.6964,  0.0696,  0.3036,  0.6964],\n",
      "        [ 0.9598,  0.5825,  1.1369,  0.0696,  1.0095,  1.1369],\n",
      "        [ 0.9304,  0.1172, -0.1369,  0.8719, -0.0914, -0.1369],\n",
      "        [ 0.9812,  0.8828,  1.0914,  0.1281,  1.1369,  1.0914],\n",
      "        [ 1.0462, -0.0792,  0.3036,  1.1303, -0.0095,  0.3036],\n",
      "        [ 0.0696, -0.0312, -0.0125,  0.5000,  0.0243, -0.0125],\n",
      "        [ 0.9598,  0.7414,  1.1369, -0.0365,  1.0095,  1.1369],\n",
      "        [ 0.9420, -0.1244, -0.0914, -0.0365,  0.0179, -0.0914],\n",
      "        [ 0.9420,  0.0763, -0.0914, -0.0986,  0.0179, -0.0914],\n",
      "        [ 0.9420, -0.0444, -0.0914,  0.0696,  0.0179, -0.0914],\n",
      "        [ 0.9304,  0.0026, -0.1369,  0.1281, -0.0914, -0.1369],\n",
      "        [ 0.9920,  0.9980,  1.0095,  0.8719,  0.6964,  1.0095],\n",
      "        [ 0.0696, -0.0208, -0.0125,  0.9304,  0.0243, -0.0125],\n",
      "        [ 0.0100,  0.0285,  0.0243,  0.1281,  0.0180,  0.0243],\n",
      "        [ 0.9598,  0.9974,  1.1369, -0.0365,  1.0095,  1.1369],\n",
      "        [ 1.0365, -0.1244,  0.0179,  0.1281,  0.0757,  0.0179],\n",
      "        [ 0.0696, -0.0327, -0.0125,  1.1303,  0.0243, -0.0125],\n",
      "        [-0.0365, -0.0208, -0.0038,  1.0236, -0.0330, -0.0038],\n",
      "        [ 0.9900,  0.4175, -0.0095,  0.5000, -0.1369, -0.0095],\n",
      "        [ 0.0696, -0.0208, -0.0125,  0.5000,  0.0243, -0.0125],\n",
      "        [ 0.9920,  0.7414,  1.0095,  0.1281,  0.6964,  1.0095],\n",
      "        [ 1.1303, -0.0481,  0.0757,  0.0696,  0.0446,  0.0757],\n",
      "        [ 0.0580, -0.0047, -0.0330,  1.1303, -0.0125, -0.0330],\n",
      "        [ 0.9900, -0.0792, -0.0095, -0.0418, -0.1369, -0.0095],\n",
      "        [ 1.0012,  0.9589,  1.0524,  0.9420,  1.0235,  1.0524],\n",
      "        [ 0.9420, -0.1244, -0.0914, -0.0986,  0.0179, -0.0914],\n",
      "        [ 0.0100, -0.0047,  0.0243,  0.1281,  0.0180,  0.0243],\n",
      "        [ 1.0236,  1.0444,  0.9821,  0.1281,  1.0914,  0.9821],\n",
      "        [ 0.9918,  1.1244,  0.9554,  0.8719,  0.9243,  0.9554],\n",
      "        [ 1.0286,  1.0897,  0.9243,  0.1281,  0.9821,  0.9243],\n",
      "        [ 1.0236,  1.1392,  0.9821, -0.1303,  1.0914,  0.9821],\n",
      "        [ 0.0696, -0.0312, -0.0125,  0.9900,  0.0243, -0.0125],\n",
      "        [ 0.0696, -0.0312, -0.0125,  1.1303,  0.0243, -0.0125],\n",
      "        [ 0.9812,  0.7414,  1.0914,  0.8719,  1.1369,  1.0914],\n",
      "        [ 1.0236,  1.1244,  0.9821,  1.0986,  1.0914,  0.9821],\n",
      "        [ 0.0580,  0.0122, -0.0330, -0.0462, -0.0125, -0.0330],\n",
      "        [ 0.9918,  1.0792,  0.9554,  1.1303,  0.9243,  0.9554],\n",
      "        [ 0.0696, -0.0047, -0.0125,  0.1281,  0.0243, -0.0125],\n",
      "        [ 0.9812,  0.5825,  1.0914,  0.0696,  1.1369,  1.0914],\n",
      "        [ 1.0236,  1.0792,  0.9821,  0.5000,  1.0914,  0.9821],\n",
      "        [ 0.0696,  0.0122, -0.0125,  0.8719,  0.0243, -0.0125],\n",
      "        [ 0.0696, -0.0047, -0.0125,  0.9420,  0.0243, -0.0125],\n",
      "        [ 1.0462,  1.0897,  0.3036,  0.1281, -0.0095,  0.3036],\n",
      "        [ 0.0580, -0.0047, -0.0330,  1.0365, -0.0125, -0.0330],\n",
      "        [ 0.0696,  0.0122, -0.0125,  0.1281,  0.0243, -0.0125],\n",
      "        [-0.0365, -0.0327, -0.0038,  1.0462, -0.0330, -0.0038],\n",
      "        [ 0.9420, -0.0444, -0.0914, -0.0462,  0.0179, -0.0914],\n",
      "        [ 0.9918,  1.0444,  0.9554,  0.8719,  0.9243,  0.9554],\n",
      "        [ 1.0236,  0.9777,  0.9821,  0.1281,  1.0914,  0.9821],\n",
      "        [ 0.0696, -0.0047, -0.0125,  1.0365,  0.0243, -0.0125],\n",
      "        [ 0.0696, -0.0208, -0.0125,  0.5000,  0.0243, -0.0125],\n",
      "        [ 0.0696, -0.0047, -0.0125,  1.1303,  0.0243, -0.0125],\n",
      "        [ 0.9420, -0.0792, -0.0914, -0.1303,  0.0179, -0.0914],\n",
      "        [ 0.9304, -0.1258, -0.1369,  0.1281, -0.0914, -0.1369],\n",
      "        [ 0.0696,  0.0246, -0.0125,  0.8719,  0.0243, -0.0125],\n",
      "        [-0.1303, -0.0327,  0.0357,  1.0986, -0.0038,  0.0357],\n",
      "        [ 0.9420, -0.1392, -0.0914, -0.0986,  0.0179, -0.0914],\n",
      "        [-0.0365, -0.0208, -0.0038,  1.1303, -0.0330, -0.0038],\n",
      "        [ 0.9918,  1.0481,  0.9554,  0.0580,  0.9243,  0.9554],\n",
      "        [ 1.0986,  0.0223,  0.0446,  0.0100, -0.0235,  0.0446],\n",
      "        [ 0.9812,  0.9304,  1.0914,  0.9900,  1.1369,  1.0914],\n",
      "        [ 0.9304, -0.1258, -0.1369,  0.5000, -0.0914, -0.1369],\n",
      "        [ 0.0100, -0.0208,  0.0243,  0.9920,  0.0180,  0.0243],\n",
      "        [ 0.9920,  0.2586,  1.0095,  0.1281,  0.6964,  1.0095],\n",
      "        [ 0.0696,  0.0246, -0.0125,  1.0418,  0.0243, -0.0125],\n",
      "        [ 0.9812,  1.0070,  1.0914, -0.1303,  1.1369,  1.0914],\n",
      "        [ 0.0580, -0.0208, -0.0330,  0.9900, -0.0125, -0.0330],\n",
      "        [ 0.0696, -0.0312, -0.0125,  0.8719,  0.0243, -0.0125],\n",
      "        [ 0.9598,  0.9589,  1.1369, -0.1303,  1.0095,  1.1369],\n",
      "        [ 0.0696, -0.0047, -0.0125,  1.0986,  0.0243, -0.0125],\n",
      "        [ 0.9718,  1.1392,  1.0235,  1.1303,  0.9554,  1.0235],\n",
      "        [ 0.9420, -0.0897, -0.0914, -0.1303,  0.0179, -0.0914],\n",
      "        [ 1.0365,  0.0020,  0.0179, -0.0365,  0.0757,  0.0179],\n",
      "        [ 1.0986,  0.0696,  0.0446,  0.0580, -0.0235,  0.0446],\n",
      "        [ 0.9918,  0.9974,  0.9554,  0.8719,  0.9243,  0.9554],\n",
      "        [ 0.9918,  0.8828,  0.9554,  0.1281,  0.9243,  0.9554],\n",
      "        [ 0.9900,  0.4175, -0.0095,  0.0696, -0.1369, -0.0095],\n",
      "        [ 1.0418,  0.5825,  0.6964,  0.1281,  0.3036,  0.6964],\n",
      "        [ 0.0696, -0.0312, -0.0125,  0.1281,  0.0243, -0.0125],\n",
      "        [ 1.0986,  0.0668,  0.0446,  0.0100, -0.0235,  0.0446],\n",
      "        [ 0.9718,  1.1392,  1.0235,  0.5000,  0.9554,  1.0235],\n",
      "        [ 0.9598,  0.7414,  1.1369, -0.0365,  1.0095,  1.1369],\n",
      "        [ 0.0696, -0.0208, -0.0125,  1.1303,  0.0243, -0.0125],\n",
      "        [ 0.9420,  0.0026, -0.0914, -0.0986,  0.0179, -0.0914],\n",
      "        [ 0.9420, -0.0897, -0.0914,  0.1281,  0.0179, -0.0914],\n",
      "        [ 0.9920,  0.2586,  1.0095,  0.8719,  0.6964,  1.0095],\n",
      "        [ 0.9420, -0.1258, -0.0914, -0.0462,  0.0179, -0.0914],\n",
      "        [ 0.0696,  0.0122, -0.0125,  1.0365,  0.0243, -0.0125],\n",
      "        [-0.0365, -0.0208, -0.0038,  0.9304, -0.0330, -0.0038],\n",
      "        [ 0.0100, -0.0208,  0.0243,  0.5000,  0.0180,  0.0243],\n",
      "        [ 0.9920,  1.1392,  1.0095, -0.0986,  0.6964,  1.0095],\n",
      "        [ 1.0986, -0.0897,  0.0446, -0.0365, -0.0235,  0.0446],\n",
      "        [ 1.0286,  1.0070,  0.9243,  0.9900,  0.9821,  0.9243],\n",
      "        [ 0.0696, -0.0047, -0.0125,  0.8719,  0.0243, -0.0125]],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> weight\n",
      "Parameter containing:\n",
      "tensor([[-1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 1., -1., -1.,  0.,  0.,  0.],\n",
      "        [ 1., -1.,  1., -1.,  0.,  0.],\n",
      "        [ 1., -1.,  1.,  1.,  0.,  0.],\n",
      "        [ 1.,  1.,  0.,  0., -1., -1.],\n",
      "        [ 1.,  1.,  0.,  0., -1.,  1.],\n",
      "        [ 1.,  1.,  0.,  0.,  1.,  0.]], requires_grad=True)\n",
      "ipdb> exit()\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = bit.linear.weight.data.numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = X.shape[1]\n",
    "comparisons = {}\n",
    "\n",
    "for i in range(n_nodes):\n",
    "    if not is_leaves[i] and children_right[i]:\n",
    "        w = np.zeros(d)\n",
    "        w[feature[i]] = 1\n",
    "        b = - np.array([threshold[i]])\n",
    "        comparisons[children_right[i]] = dict(\n",
    "            w=w,\n",
    "            b=b\n",
    "        )\n",
    "    if not is_leaves[i] and children_left[i]:\n",
    "        w = np.zeros(d)\n",
    "        w[feature[i]] = -1\n",
    "        b = np.array([threshold[i]])\n",
    "        comparisons[children_left[i]] = dict(\n",
    "            w=w,\n",
    "            b=b\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(comparisons).T.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.stack(df.w.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.stack(df.b.values).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "lin = nn.Linear(4,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin.weight.data = torch.tensor(W)\n",
    "lin.bias.data = torch.tensor(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5229, 0.4771, 0.3238,  ..., 0.6096, 0.3904, 0.3805],\n",
       "        [0.5229, 0.4771, 0.3238,  ..., 0.6096, 0.3904, 0.3805],\n",
       "        [0.5229, 0.4771, 0.3461,  ..., 0.6096, 0.3904, 0.3805],\n",
       "        ...,\n",
       "        [0.1534, 0.8466, 0.0106,  ..., 0.2052, 0.7948, 0.7879],\n",
       "        [0.1183, 0.8817, 0.0087,  ..., 0.1605, 0.8395, 0.8338],\n",
       "        [0.1812, 0.8188, 0.0117,  ..., 0.2397, 0.7603, 0.7526]],\n",
       "       dtype=torch.float64, grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(lin(torch.tensor(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  ..., False, False, False],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.sigmoid(torch.tensor(np.matmul(W,X.T) + b)) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "comparisons = OrderedDict(sorted(comparisons.items(), key=lambda t: t[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(1, {'w': array([ 0.,  0.,  0., -1.]), 'b': array([0.29166666])}),\n",
       "             (2, {'w': array([0., 0., 0., 1.]), 'b': array([-0.29166666])}),\n",
       "             (3, {'w': array([ 0.,  0., -1.,  0.]), 'b': array([0.66379309])}),\n",
       "             (4, {'w': array([ 0.,  0.,  0., -1.]), 'b': array([0.64583334])}),\n",
       "             (5, {'w': array([0., 0., 0., 1.]), 'b': array([-0.64583334])}),\n",
       "             (6, {'w': array([ 0., -1.,  0.,  0.]), 'b': array([0.45833333])}),\n",
       "             (7, {'w': array([0., 1., 0., 0.]), 'b': array([-0.45833333])}),\n",
       "             (8, {'w': array([0., 0., 1., 0.]), 'b': array([-0.66379309])}),\n",
       "             (9, {'w': array([ 0.,  0.,  0., -1.]), 'b': array([0.6875])}),\n",
       "             (10,\n",
       "              {'w': array([ 0.,  0.,  0., -1.]), 'b': array([0.64583334])}),\n",
       "             (11, {'w': array([0., 0., 0., 1.]), 'b': array([-0.64583334])}),\n",
       "             (12, {'w': array([0., 0., 0., 1.]), 'b': array([-0.6875])})])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_values([{'w': array([ 0.,  0.,  0., -1.]), 'b': array([0.29166666])}, {'w': array([0., 0., 0., 1.]), 'b': array([-0.29166666])}, {'w': array([ 0.,  0., -1.,  0.]), 'b': array([0.66379309])}, {'w': array([ 0.,  0.,  0., -1.]), 'b': array([0.64583334])}, {'w': array([0., 0., 0., 1.]), 'b': array([-0.64583334])}, {'w': array([ 0., -1.,  0.,  0.]), 'b': array([0.45833333])}, {'w': array([0., 1., 0., 0.]), 'b': array([-0.45833333])}, {'w': array([0., 0., 1., 0.]), 'b': array([-0.66379309])}, {'w': array([ 0.,  0.,  0., -1.]), 'b': array([0.6875])}, {'w': array([ 0.,  0.,  0., -1.]), 'b': array([0.64583334])}, {'w': array([0., 0., 0., 1.]), 'b': array([-0.64583334])}, {'w': array([0., 0., 0., 1.]), 'b': array([-0.6875])}])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparisons.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1331583041478315\n",
      "-0.13315830414783147\n",
      "-0.13315830414783186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 0.1\n",
    "print(p_sigmoid(t))\n",
    "print(1-p_sigmoid(t)), print(p_sigmoid(-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.80000001, -2.        ,  4.95000005, -2.        , -2.        ])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0,1,1]\n",
    "n = len(a)\n",
    "\n",
    "products = [[0,1]] * n\n",
    "\n",
    "x = list(itertools.product(*products))\n",
    "x = np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "eq() received an invalid combination of arguments - got (list), but expected one of:\n * (Tensor other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mlist\u001b[0m)\n * (Number other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mlist\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-1294190defb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: eq() received an invalid combination of arguments - got (list), but expected one of:\n * (Tensor other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mlist\u001b[0m)\n * (Number other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mlist\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "torch.tensor(x) == "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcomparison.linear.weight.data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
